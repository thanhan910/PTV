{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import geopandas as gpd\n",
    "import dask.dataframe as dd\n",
    "import os\n",
    "from dbfread import DBF\n",
    "from tqdm import tqdm\n",
    "import fiona\n",
    "from fiona.crs import from_epsg\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHP_DIR = '../local/ptv-datashare-orders/PTV'\n",
    "SHP_GDFK_PTV : gpd.GeoDataFrame = { f.split('.')[0]: gpd.read_file(os.path.join(SHP_DIR, f)) for f in os.listdir(SHP_DIR) if f.endswith('.shp') }\n",
    "for f in os.listdir(SHP_DIR):\n",
    "    if f.endswith('.txt'):\n",
    "        gdf_name = f.removesuffix('_column_names.txt').upper()\n",
    "        with open(os.path.join(SHP_DIR, f), 'r') as file:\n",
    "            gdf_column_names = [line.strip() for line in file.readlines()][4:]\n",
    "        assert gdf_name in SHP_GDFK_PTV, f'{gdf_name} not in GDFS'\n",
    "        for line in gdf_column_names:\n",
    "            assert ' = ' in line, f'Invalid line: {line}'\n",
    "        gdf_column_names = { line.split(' = ')[0]: line.split(' = ')[1] for line in gdf_column_names }\n",
    "        SHP_GDFK_PTV[gdf_name].rename(columns=gdf_column_names, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = '../local/ptv-datashare-orders/VMTRANS/tr_road_column_names.txt'\n",
    "gdf_name = f.removesuffix('_column_names.txt').upper()\n",
    "with open(f) as file:\n",
    "    gdf_column_names = [line.strip() for line in file.readlines()][4:]\n",
    "for line in gdf_column_names:\n",
    "    assert ' = ' in line, f'Invalid line: {line}'\n",
    "gdf_column_names = { line.split(' = ')[0]: line.split(' = ')[1] for line in gdf_column_names }\n",
    "# SHP_GDFK_PTV[gdf_name].rename(columns=gdf_column_names, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHP_VICROADS_FILES = [(int(f.split('.')[0].split('-')[1]), os.path.join('../local/ptv-datashare-orders/VMTRANS_split/', f)) for f in os.listdir('../local/ptv-datashare-orders/VMTRANS_split/') if f.endswith('.shp')]\n",
    "# SHP_VICROADS_FILES = sorted(SHP_VICROADS_FILES, key=lambda x: x[0])\n",
    "# SHP_VICROADS_FILES = SHP_VICROADS_FILES[:-1]\n",
    "# SHP_GDFK_VICROADS = {}\n",
    "\n",
    "# with tqdm(total=len(SHP_VICROADS_FILES)) as pbar:\n",
    "#     for gdf_name, filepath in SHP_VICROADS_FILES:\n",
    "#         SHP_GDFK_VICROADS[gdf_name] = gpd.read_file(filepath)\n",
    "#         pbar.update(1)\n",
    "# 350m - 6 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GDF_VICROADS : gpd.GeoDataFrame = gpd.GeoDataFrame(pd.concat(SHP_GDFK_VICROADS.values(), ignore_index=True))\n",
    "# GDF_VICROADS.rename(columns=gdf_column_names, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [04:17<00:00,  1.94it/s]\n",
      "C:\\Users\\An\\AppData\\Local\\Temp\\ipykernel_23132\\321312405.py:12: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  GDF_MELROADS : gpd.GeoDataFrame = gpd.GeoDataFrame(pd.concat(SHP_GDFK_MELROADS.values(), ignore_index=True))\n"
     ]
    }
   ],
   "source": [
    "SHP_MELROADS_FILES = [(int(f.split('.')[0].split('-')[1]), os.path.join('../local/ptv-datashare-orders/VMTRANS_MEL_split/', f)) for f in os.listdir('../local/ptv-datashare-orders/VMTRANS_MEL_split/') if f.endswith('.shp')]\n",
    "SHP_MELROADS_FILES = sorted(SHP_MELROADS_FILES, key=lambda x: x[0])\n",
    "SHP_MELROADS_FILES = SHP_MELROADS_FILES[:-1]\n",
    "SHP_GDFK_MELROADS = {}\n",
    "\n",
    "with tqdm(total=len(SHP_MELROADS_FILES)) as pbar:\n",
    "    for gdf_name, filepath in SHP_MELROADS_FILES:\n",
    "        SHP_GDFK_MELROADS[gdf_name] = gpd.read_file(filepath)\n",
    "        pbar.update(1)\n",
    "# 5m - 10m\n",
    "        \n",
    "GDF_MELROADS : gpd.GeoDataFrame = gpd.GeoDataFrame(pd.concat(SHP_GDFK_MELROADS.values(), ignore_index=True))\n",
    "# 2s - 5s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "GDF_MELROADS.rename(columns=gdf_column_names, inplace=True)\n",
    "\n",
    "for col in GDF_MELROADS.columns:\n",
    "    if GDF_MELROADS[col].isna().all():\n",
    "        GDF_MELROADS.drop(columns=[col], inplace=True)\n",
    "        # 7s\n",
    "GDF_MELROADS['length'] = GDF_MELROADS.geometry.to_crs(epsg=3857).length\n",
    "GDF_MELROADS['line'] = GDF_MELROADS.geometry.apply(lambda x: x.coords)\n",
    "GDF_MELROADS['line_start'] = GDF_MELROADS['line'].apply(lambda x: x[0])\n",
    "GDF_MELROADS['line_end'] = GDF_MELROADS['line'].apply(lambda x: x[-1])\n",
    "assert GDF_MELROADS.groupby(['FROM_UFI'])['line_start'].nunique().unique() == [1]\n",
    "assert GDF_MELROADS.groupby(['TO_UFI'])['line_end'].nunique().unique() == [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GDF_MELROADS.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GDF_MELROADS[GDF_MELROADS['LEFT_LOCALITY'] != GDF_MELROADS['RIGHT_LOCALITY']][['EZI_ROAD_NAME', 'LEFT_LOCALITY', 'RIGHT_LOCALITY', 'geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shp2pgsql -s 7844 -I TR_ROAD.shp tr_road | psql  -d gis_db -U postgres >> log.txt 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file('../local/ptv-spatial-datasets/PTV_METRO_TRAIN_STATION.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LATITUDE     -37.809939\n",
       "LONGITUDE    144.962594\n",
       "Name: 92, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf[gdf['STOP_NAME'].str.contains(\"Melbourne Central\")][['LATITUDE', 'LONGITUDE']].iloc[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
