{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHP_DIR = '../local/ptv-spatial-datasets'\n",
    "SHP_GDFS : gpd.GeoDataFrame = { f.split('.')[0]: gpd.read_file(os.path.join(SHP_DIR, f)) for f in os.listdir(SHP_DIR) if f.endswith('.shp') }\n",
    "for f in os.listdir(SHP_DIR):\n",
    "    if f.endswith('.txt'):\n",
    "        gdf_name = f.removesuffix('_column_names.txt').upper()\n",
    "        with open(os.path.join(SHP_DIR, f), 'r') as file:\n",
    "            gdf_column_names = [line.strip() for line in file.readlines()][4:]\n",
    "        assert gdf_name in SHP_GDFS, f'{gdf_name} not in GDFS'\n",
    "        for line in gdf_column_names:\n",
    "            assert ' = ' in line, f'Invalid line: {line}'\n",
    "        gdf_column_names = { line.split(' = ')[0]: line.split(' = ')[1] for line in gdf_column_names }\n",
    "        SHP_GDFS[gdf_name].rename(columns=gdf_column_names, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert SHP_GDFS['PTV_METRO_BUS_STOP']['ROUTES_USING_STOP'].notna().all()\n",
    "assert SHP_GDFS['PTV_METRO_TRAM_STOP']['ROUTES_USING_STOP'].notna().all()\n",
    "assert SHP_GDFS['PTV_METRO_TRAIN_STATION']['ROUTES_USING_STOP'].notna().all()\n",
    "# Check if a column exists in a GeoDataFrame\n",
    "assert 'ROUTES_USING_STOP' not in SHP_GDFS['PTV_REGIONAL_COACH_STOP'].columns\n",
    "assert SHP_GDFS['PTV_SKYBUS_STOP']['ROUTES_USING_STOP'].isna().all()\n",
    "assert SHP_GDFS['PTV_REGIONAL_BUS_STOP']['ROUTES_USING_STOP'].notna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "shp_gdf_routes = []\n",
    "for k, gdf in SHP_GDFS.items():\n",
    "    if 'ROUTE' in k:\n",
    "        gdf['SHP_FILE'] = k\n",
    "        shp_gdf_routes.append(gdf)\n",
    "SHP_DF_ROUTES : pd.DataFrame = pd.concat(shp_gdf_routes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SHP_FILE</th>\n",
       "      <th>route_id0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>PTV_METRO_BUS_ROUTE</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>PTV_METRO_BUS_ROUTE</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PTV_METRO_TRAM_ROUTE</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>PTV_REGIONAL_BUS_ROUTE</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>PTV_REGIONAL_COACH_ROUTE</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PTV_SKYBUS_ROUTE</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     SHP_FILE route_id0\n",
       "33        PTV_METRO_BUS_ROUTE         4\n",
       "763       PTV_METRO_BUS_ROUTE         7\n",
       "9        PTV_METRO_TRAM_ROUTE         3\n",
       "434    PTV_REGIONAL_BUS_ROUTE         6\n",
       "386  PTV_REGIONAL_COACH_ROUTE         5\n",
       "0            PTV_SKYBUS_ROUTE        11"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SHP_DF_ROUTES['route_idx'] = SHP_DF_ROUTES['ROUTE_ID'].apply(lambda x: x.split('-'))\n",
    "SHP_DF_ROUTES['route_id0'] = SHP_DF_ROUTES['route_idx'].apply(lambda x: x[0])\n",
    "SHP_DF_ROUTES['route_id1'] = SHP_DF_ROUTES['route_idx'].apply(lambda x: x[1])\n",
    "SHP_DF_ROUTES['route_id2'] = SHP_DF_ROUTES['route_idx'].apply(lambda x: x[2] if len(x) > 4 else np.nan)\n",
    "SHP_DF_ROUTES['route_id3'] = SHP_DF_ROUTES['route_idx'].apply(lambda x: x[-2])\n",
    "SHP_DF_ROUTES['route_id4'] = SHP_DF_ROUTES['route_idx'].apply(lambda x: x[-1])\n",
    "SHP_DF_ROUTES['route_id01'] = SHP_DF_ROUTES['route_id0'] + '-' + SHP_DF_ROUTES['route_id1']\n",
    "\n",
    "assert SHP_DF_ROUTES.groupby('route_id01').aggregate({'route_id2': 'unique', 'route_id3': 'unique', 'route_id4': 'unique'}).apply(lambda x: len(x['route_id2']) <= 1 or len(x['route_id4']) <= 1, axis=1).all()\n",
    "\n",
    "# Since ROUTE_LONG_NAME is all not null, when we merge dataframes, we can use ROUTE_LONG_NAME isna() to check if the other dataframe has the equivalent data in SHP_DF_ROUTES_MIN\n",
    "assert SHP_DF_ROUTES['ROUTE_LONG_NAME'].notna().all()\n",
    "\n",
    "# Inspect the route_id0 values of SHP_DF_ROUTES\n",
    "SHP_DF_ROUTES['route_id0'].sort_values(key=lambda x: x.apply(int)).unique() # array(['3', '4', '5', '6', '7', '11'], dtype=object)\n",
    "\n",
    "# Assert that all metro buses route_short_name are 3 or 4 characters long\n",
    "assert SHP_DF_ROUTES[(SHP_DF_ROUTES['route_id0'] == '4')]['ROUTE_SHORT_NAME'].apply(lambda x: len(x) in [3, 4]).all()\n",
    "# Proof that route_id1 is unique for each ROUTE_SHORT_NAME for route_id0 == 4\n",
    "odd_bus_id1_names = SHP_DF_ROUTES[(SHP_DF_ROUTES['route_id1'] != SHP_DF_ROUTES['ROUTE_SHORT_NAME']) & (SHP_DF_ROUTES['route_id0'] == '4')]['ROUTE_SHORT_NAME'].unique()\n",
    "assert SHP_DF_ROUTES[(SHP_DF_ROUTES['ROUTE_SHORT_NAME'].apply(lambda x: x in odd_bus_id1_names)) & (SHP_DF_ROUTES['route_id0'] == '4')].groupby('ROUTE_SHORT_NAME')['route_id1'].nunique().unique() == [1]\n",
    "\n",
    "def get_gtfs_id(x):\n",
    "    if x['route_id0'] == '4':\n",
    "        return f'4-{x[\"ROUTE_SHORT_NAME\"]}'\n",
    "    elif x['route_id0'] == '7':\n",
    "        assert 'TB' in x[\"route_id1\"], f'7-TeleBus route_id1 {x[\"route_id1\"]} does not contain TB'\n",
    "        route_number = x[\"route_id1\"].lstrip('TB')\n",
    "        # Add left trailing 0s\n",
    "        route_number = route_number.zfill(2)\n",
    "        return f'7-B{route_number}'\n",
    "    else:\n",
    "        return f'{x[\"route_id0\"]}-{x[\"route_id1\"]}'\n",
    "\n",
    "SHP_DF_ROUTES['route_shp_id'] = SHP_DF_ROUTES.apply(lambda x: f'{x[\"route_id0\"]}-{x[\"route_id1\"]}' + (x['route_id2'] if x['route_id0'] == '4' and pd.notna(x['route_id2']) else ''), axis=1)\n",
    "SHP_DF_ROUTES['route_gtfs_id'] = SHP_DF_ROUTES.apply(lambda x: get_gtfs_id(x), axis=1)\n",
    "\n",
    "SHP_DF_ROUTES_MIN = SHP_DF_ROUTES[['route_gtfs_id', 'route_shp_id', 'route_id0', 'ROUTE_SHORT_NAME', 'ROUTE_LONG_NAME', 'SHP_FILE']].drop_duplicates()\n",
    "\n",
    "SHP_DF_ROUTES_MIN = SHP_DF_ROUTES_MIN.groupby('route_gtfs_id').aggregate({'route_shp_id': 'unique', 'route_id0': 'unique', 'ROUTE_SHORT_NAME': 'unique', 'ROUTE_LONG_NAME': 'unique', 'SHP_FILE': 'unique'}).reset_index()\n",
    "\n",
    "assert SHP_DF_ROUTES_MIN['route_shp_id'].apply(lambda x: len(x) == 1).all()\n",
    "assert SHP_DF_ROUTES_MIN['route_id0'].apply(lambda x: len(x) == 1).all()\n",
    "assert SHP_DF_ROUTES_MIN['ROUTE_SHORT_NAME'].apply(lambda x: len(x) == 1).all()\n",
    "assert SHP_DF_ROUTES_MIN['SHP_FILE'].apply(lambda x: len(x) == 1).all()\n",
    "\n",
    "# Inspect multiple ROUTE_LONG_NAME of the same route_gtfs_id\n",
    "SHP_DF_ROUTES_MIN[SHP_DF_ROUTES_MIN['ROUTE_LONG_NAME'].apply(lambda x: len(x) != 1)]\n",
    "\n",
    "SHP_DF_ROUTES_MIN['route_shp_id'] = SHP_DF_ROUTES_MIN['route_shp_id'].apply(lambda x: x[0])\n",
    "SHP_DF_ROUTES_MIN['route_id0'] = SHP_DF_ROUTES_MIN['route_id0'].apply(lambda x: x[0])\n",
    "SHP_DF_ROUTES_MIN['ROUTE_SHORT_NAME'] = SHP_DF_ROUTES_MIN['ROUTE_SHORT_NAME'].apply(lambda x: x[0])\n",
    "SHP_DF_ROUTES_MIN['SHP_FILE'] = SHP_DF_ROUTES_MIN['SHP_FILE'].apply(lambda x: x[0])\n",
    "\n",
    "SHP_DF_ROUTES_MIN[['SHP_FILE', 'route_id0']].drop_duplicates().sort_values('SHP_FILE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert SHP_GDFS['PTV_METRO_TRAM_STOP']['STOP_ID'].is_unique\n",
    "assert SHP_GDFS['PTV_METRO_TRAIN_STATION']['STOP_ID'].is_unique\n",
    "assert SHP_GDFS['PTV_REGIONAL_BUS_STOP']['STOP_ID'].is_unique\n",
    "assert SHP_GDFS['PTV_REGIONAL_COACH_STOP']['STOP_ID'].is_unique\n",
    "assert SHP_GDFS['PTV_SKYBUS_STOP']['STOP_ID'].is_unique\n",
    "\n",
    "# STOP ID in PTV_METRO_BUS_STOP is not unique, however it's only because of the addition of TeleBus routes\n",
    "shp_metro_bus_stop_duplicated_ids = SHP_GDFS['PTV_METRO_BUS_STOP'][SHP_GDFS['PTV_METRO_BUS_STOP']['STOP_ID'].duplicated(keep=False)].groupby('STOP_ID')['ROUTES_USING_STOP'].unique()\n",
    "assert shp_metro_bus_stop_duplicated_ids.apply(lambda x: len(x) == 2).all()\n",
    "assert shp_metro_bus_stop_duplicated_ids.apply(lambda x: len([i for i in x if 'TeleBus' in i]) == 1).all()\n",
    "\n",
    "# Split PTV_METRO_BUS_STOP into PTV_METROBUS_STOP and PTV_TELEBUS_STOP\n",
    "SHP_GDFS['PTV_METROBUS_STOP'] = SHP_GDFS['PTV_METRO_BUS_STOP'][SHP_GDFS['PTV_METRO_BUS_STOP']['ROUTES_USING_STOP'].apply(lambda x: 'TeleBus' not in x)].reset_index(drop=True)\n",
    "SHP_GDFS['PTV_TELEBUS_STOP'] = SHP_GDFS['PTV_METRO_BUS_STOP'][SHP_GDFS['PTV_METRO_BUS_STOP']['ROUTES_USING_STOP'].apply(lambda x: 'TeleBus' in x)].reset_index(drop=True)\n",
    "\n",
    "assert SHP_GDFS['PTV_METROBUS_STOP']['STOP_ID'].is_unique\n",
    "assert SHP_GDFS['PTV_TELEBUS_STOP']['STOP_ID'].is_unique\n",
    "\n",
    "SHP_DFS_STOPS = {\n",
    "    '2': SHP_GDFS['PTV_METRO_TRAIN_STATION'],\n",
    "    '3': SHP_GDFS['PTV_METRO_TRAM_STOP'],\n",
    "    '4': SHP_GDFS['PTV_METROBUS_STOP'],\n",
    "    '5': SHP_GDFS['PTV_REGIONAL_COACH_STOP'],\n",
    "    '6': SHP_GDFS['PTV_REGIONAL_BUS_STOP'],\n",
    "    '7': SHP_GDFS['PTV_TELEBUS_STOP'],\n",
    "    '11': SHP_GDFS['PTV_SKYBUS_STOP']\n",
    "}\n",
    "\n",
    "for mid in SHP_DFS_STOPS:\n",
    "    if 'ROUTES_USING_STOP' in SHP_DFS_STOPS[mid].columns:\n",
    "        SHP_DFS_STOPS[mid]['ROUTE'] = SHP_DFS_STOPS[mid]['ROUTES_USING_STOP'].apply(lambda x: x.split(',') if pd.notna(x) else [])\n",
    "        SHP_DFS_STOPS[mid] = SHP_DFS_STOPS[mid][['STOP_ID', 'ROUTE']].explode('ROUTE').reset_index(drop=True)\n",
    "\n",
    "for k in SHP_DFS_STOPS:\n",
    "    if 'ROUTE' in SHP_DFS_STOPS[k].columns:\n",
    "        SHP_DFS_STOPS[k] = SHP_DFS_STOPS[k].merge(SHP_DF_ROUTES_MIN[SHP_DF_ROUTES_MIN['route_id0'] == k], left_on='ROUTE', right_on='ROUTE_SHORT_NAME', how='left')\n",
    "\n",
    "# Assert that there is no odd ROUTE in SHP_DFS_STOPS\n",
    "assert SHP_DFS_STOPS['3']['ROUTE_SHORT_NAME'].notna().all()\n",
    "assert SHP_DFS_STOPS['4']['ROUTE_SHORT_NAME'].notna().all()\n",
    "assert SHP_DFS_STOPS['7']['ROUTE_SHORT_NAME'].notna().all()\n",
    "assert 'ROUTE' not in SHP_DFS_STOPS['5'].columns\n",
    "assert (SHP_DFS_STOPS['6'][SHP_DFS_STOPS['6']['ROUTE'].notna() & SHP_DFS_STOPS['6']['ROUTE_SHORT_NAME'].isna()]['ROUTE'] == '').all()\n",
    "assert (SHP_DFS_STOPS['11'][SHP_DFS_STOPS['11']['ROUTE'].notna() & SHP_DFS_STOPS['11']['ROUTE_SHORT_NAME'].isna()]['ROUTE'] == '').all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
