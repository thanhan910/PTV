{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hashlib import sha1\n",
    "import hmac\n",
    "import requests\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import pyptvgtfs\n",
    "import csv\n",
    "SESSION = requests.Session()\n",
    "\n",
    "ENV = json.load(open('../local-env.json'))\n",
    "\n",
    "def get_ptv_api_url(\n",
    "        endpoint : str,\n",
    "        dev_id : str | int, \n",
    "        api_key : str | int,\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Returns the URL to use PTV TimeTable API.\n",
    "\n",
    "    Generates a signature from dev id (user id), API key, and endpoint.\n",
    "\n",
    "    See the following for more information:\n",
    "    - Home page: https://www.ptv.vic.gov.au/footer/data-and-reporting/datasets/ptv-timetable-api/\n",
    "    - Swagger UI: https://timetableapi.ptv.vic.gov.au/swagger/ui/index\n",
    "    - Swagger Docs JSON: https://timetableapi.ptv.vic.gov.au/swagger/docs/v3 (You can use this to find the endpoints you want to use.)\n",
    "    \"\"\"\n",
    "    assert endpoint.startswith('/'), f'Endpoint must start with /, got {endpoint}'\n",
    "    raw = f'{endpoint}{'&' if '?' in endpoint else '?'}devid={dev_id}'\n",
    "    hashed = hmac.new(api_key.encode('utf-8'), raw.encode('utf-8'), sha1)  # Encode the raw string to bytes\n",
    "    signature = hashed.hexdigest()\n",
    "    return f'https://timetableapi.ptv.vic.gov.au{raw}&signature={signature}'\n",
    "\n",
    "\n",
    "def get_data(endpoint : str, need_auth : bool = True):\n",
    "    \"\"\"\n",
    "    Returns the data from the URL.\n",
    "    \"\"\"\n",
    "    if need_auth:\n",
    "        url = get_ptv_api_url(endpoint, ENV['PTV_TIMETABLE_DEV_ID'], ENV['PTV_TIMETABLE_API_KEY'])\n",
    "    else:\n",
    "        url = f'https://timetableapi.ptv.vic.gov.au{endpoint}'\n",
    "    response = SESSION.get(url)\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_DOCS = get_data('/swagger/docs/v3', need_auth=False)\n",
    "STATIC_API_ENDPOINTS = [k for k in API_DOCS['paths'].keys() if '{' not in k]\n",
    "API_ROUTES : dict = get_data('/v3/routes')['routes']\n",
    "API_ROUTE_TYPES : dict = get_data('/v3/route_types')['route_types']\n",
    "API_DISRUPTIONS : dict = get_data('/v3/disruptions')['disruptions']\n",
    "API_DISRUPTION_MODES : dict = get_data('/v3/disruptions/modes')['disruption_modes']\n",
    "API_OUTLETS : dict = get_data('/v3/outlets')['outlets']\n",
    "API_DF_ROUTE_TYPES = pd.DataFrame(API_ROUTE_TYPES)\n",
    "API_DF_DISRUPTION_MODES = pd.DataFrame(API_DISRUPTION_MODES)\n",
    "API_DF_OUTLETS = pd.DataFrame(API_OUTLETS)\n",
    "# There are some faulty data in the outlets data. In particular, the latitude is > 0, which is not possible in Victoria.\n",
    "API_DF_OUTLETS['outlet_latitude'] = API_DF_OUTLETS['outlet_latitude'].apply(lambda x: -x if x > 0 else x)\n",
    "for route in API_ROUTES:\n",
    "    for mid, v in route['route_service_status'].items():\n",
    "        assert mid not in route, f'Key {mid} already exists in route'\n",
    "        route[mid] = v\n",
    "    del route['route_service_status']\n",
    "\n",
    "API_DF_ROUTES = pd.DataFrame(API_ROUTES) \n",
    "assert API_DF_ROUTES['route_id'].is_unique, 'route_id is not unique'\n",
    "assert API_DF_ROUTES['route_gtfs_id'].is_unique, 'route_gtfs_id is not unique'\n",
    "API_DF_ROUTES['route_id'] = API_DF_ROUTES['route_id'].apply(str)\n",
    "API_DF_ROUTES['route_type'] = API_DF_ROUTES['route_type'].apply(lambda x: str(int(x)) if not pd.isna(x) else x)\n",
    "\n",
    "API_DF_ROUTES = API_DF_ROUTES[['route_type', 'route_id', 'route_name', 'route_number']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "GTFS = pyptvgtfs.process_gtfs_zip('../downloads/20240312_113156/gtfs.zip', '')\n",
    "GTFS.drop(columns=['version_id'], inplace=True)\n",
    "GTFS_DFS = GTFS.set_index(['mode_id', 'table_name'])['df'].to_dict()\n",
    "new_GTFS_DFS = {}\n",
    "for mid, v in GTFS_DFS.items():\n",
    "    new_GTFS_DFS[mid[0]] = new_GTFS_DFS.get(mid[0], {})\n",
    "    new_GTFS_DFS[mid[0]][mid[1]] = v\n",
    "GTFS_DFS : dict[str, dict[str, pd.DataFrame]] = new_GTFS_DFS\n",
    "for mid in GTFS_DFS:\n",
    "    for tn in GTFS_DFS[mid]:\n",
    "        GTFS_DFS[mid][tn]['mode_id'] = mid\n",
    "# 45s - 1m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "GTFS_DF_ROUTES = pd.concat([GTFS_DFS[mid]['routes'] for mid in GTFS_DFS])\n",
    "# 1m - 2m\n",
    "GTFS_DF_ROUTES['route_idx'] = GTFS_DF_ROUTES['route_id'].apply(lambda x: x.split('-'))\n",
    "GTFS_DF_ROUTES['route_id0'] = GTFS_DF_ROUTES['route_idx'].apply(lambda x: x[0])\n",
    "GTFS_DF_ROUTES['route_id1'] = GTFS_DF_ROUTES['route_idx'].apply(lambda x: x[1])\n",
    "GTFS_DF_ROUTES['route_id2'] = GTFS_DF_ROUTES['route_idx'].apply(lambda x: x[2] if len(x) > 4 else np.nan)\n",
    "GTFS_DF_ROUTES['route_id3'] = GTFS_DF_ROUTES['route_idx'].apply(lambda x: x[-2])\n",
    "GTFS_DF_ROUTES['route_id4'] = GTFS_DF_ROUTES['route_idx'].apply(lambda x: x[-1])\n",
    "GTFS_DF_ROUTES['route_id01'] = GTFS_DF_ROUTES['mode_id'] + '-' + GTFS_DF_ROUTES['route_id1']\n",
    "GTFS_DF_ROUTES['route_gtfs_id'] = GTFS_DF_ROUTES.apply(lambda x: f'{x[\"mode_id\"]}-{x[\"route_id1\"]}' + (x['route_id2'] if x['mode_id'] == '4' and pd.notna(x['route_id2']) else ''), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GTFS_DF_STOP_TIMES = pd.concat([GTFS_DFS[mid]['stop_times'] for mid in GTFS_DFS])\n",
    "GTFS_DF_TRIPS = pd.concat([GTFS_DFS[mid]['trips'] for mid in GTFS_DFS])\n",
    "GTFS_DF_TRIPS = GTFS_DF_TRIPS.merge(GTFS_DF_ROUTES, on='route_id', how='left', suffixes=('', '_route'))\n",
    "GTFS_DF_TRIPS.drop(columns=['mode_id_route'], inplace=True)\n",
    "\n",
    "# GTFS_DF_STOP_TIMES = GTFS_DF_STOP_TIMES.merge(GTFS_DF_STOPS, on='stop_id', suffixes=('', '_stop'))\n",
    "GTFS_DF_STOP_TIMES = GTFS_DF_STOP_TIMES.merge(GTFS_DF_TRIPS, on='trip_id', suffixes=('', '_trip'))\n",
    "# 1m 30s\n",
    "\n",
    "GTFS_DF_STOP_TIMES = GTFS_DF_STOP_TIMES[['stop_id', 'stop_sequence', 'mode_id', 'direction_id', 'route_gtfs_id', 'route_short_name', 'route_long_name']].drop_duplicates()\n",
    "# 20s\n",
    "GTFS_DF_ROUTESTOPS = GTFS_DF_STOP_TIMES.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "GTFS_DF_STOPS = pd.concat([GTFS_DFS[mid]['stops'] for mid in GTFS_DFS])\n",
    "GTFS_DF_STOPS['stop_lat'] = GTFS_DF_STOPS['stop_lat'].apply(np.float64)\n",
    "GTFS_DF_STOPS['stop_lon'] = GTFS_DF_STOPS['stop_lon'].apply(np.float64)\n",
    "GTFS_DF_STOPS['stop_full_name'] = GTFS_DF_STOPS['stop_name']\n",
    "\n",
    "def get_suburb(stop_full_name):\n",
    "    if '(' not in stop_full_name:\n",
    "        stop_name = stop_full_name\n",
    "        stop_suburb = np.nan\n",
    "        return (stop_name, stop_suburb)\n",
    "    parentheses_count = 0\n",
    "    for i in range(len(stop_full_name) - 1, -1, -1):\n",
    "        c = stop_full_name[i]\n",
    "        if c == ')':\n",
    "            parentheses_count += 1\n",
    "        if c == '(':\n",
    "            parentheses_count -= 1\n",
    "        if parentheses_count == 0:\n",
    "            stop_name = stop_full_name[:i].strip()\n",
    "            stop_suburb = stop_full_name[i:].removesuffix(')').lstrip('(')\n",
    "            return (stop_name, stop_suburb)\n",
    "        \n",
    "GTFS_DF_STOPS['stop_name'], GTFS_DF_STOPS['stop_suburb'] = zip(*GTFS_DF_STOPS['stop_full_name'].apply(get_suburb))\n",
    "\n",
    "# Assert no stop_name contains both ',' and '('\n",
    "assert not (GTFS_DF_STOPS['stop_suburb'].notna() & GTFS_DF_STOPS['stop_full_name'].apply(lambda x: ',' in x)).any()\n",
    "\n",
    "# Assert all stop_full_name contains at most 1 ',', and if it contains 1 ',', it must be followed by a space.\n",
    "assert GTFS_DF_STOPS['stop_full_name'].apply(lambda x: x.count(',') == x.count(', ') and x.count(',') <= 1).all()\n",
    "\n",
    "\n",
    "GTFS_DF_STOPS['stop_suburb'] = GTFS_DF_STOPS.apply(lambda x: x['stop_name'].split(', ')[0] if ',' in x['stop_name'] else x['stop_suburb'], axis=1)\n",
    "\n",
    "GTFS_DF_STOPS['stop_name'] = GTFS_DF_STOPS.apply(lambda x: x['stop_name'].split(', ')[1] if ',' in x['stop_name'] else x['stop_name'], axis=1)\n",
    "\n",
    "# Inspect NaN stop_suburb\n",
    "GTFS_DF_STOPS[GTFS_DF_STOPS['stop_suburb'].isna()]\n",
    "\n",
    "\n",
    "\n",
    "# Custom stop_name and stop_suburb\n",
    "\n",
    "def custom_stop_name(x):\n",
    "    if x['stop_id'] == '5588':\n",
    "        assert x['stop_name'] == 'Rosemary St'\n",
    "        return 'Rosemary St/High St'\n",
    "    return x['stop_name']\n",
    "\n",
    "def custom_stop_suburb(x):\n",
    "    if x['stop_id'] == '5588':\n",
    "        assert x['stop_name'] == 'Rosemary St' or x['stop_name'] == 'Rosemary St/High St', x['stop_name']\n",
    "        return 'Templestowe Lower'\n",
    "    if x['stop_id'] == '28185':\n",
    "        assert x['stop_name'] == 'Keysborough South Shopping Centre/Braeside-Dandenong Rd', x['stop_name']\n",
    "        return 'Keysborough'\n",
    "    if x['stop_id'] == '35117':\n",
    "        assert x['stop_name'] == 'Ascot St/Sturt St', x['stop_name']\n",
    "        return 'Ballarat Central'\n",
    "    return x['stop_suburb']\n",
    "\n",
    "GTFS_DF_STOPS['stop_name'] = GTFS_DF_STOPS.apply(lambda x: custom_stop_name(x), axis=1)\n",
    "GTFS_DF_STOPS['stop_suburb'] = GTFS_DF_STOPS.apply(lambda x: custom_stop_suburb(x), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "GTFS_DF_STOPS = GTFS_DF_STOPS.groupby('stop_id').aggregate({'stop_name': 'unique', 'stop_suburb': 'unique', 'stop_full_name': 'unique', 'stop_lat': 'unique', 'stop_lon': 'unique'})\n",
    "# 5s - 7s\n",
    "\n",
    "GTFS_DF_STOPS.reset_index(inplace=True)\n",
    "\n",
    "for col in GTFS_DF_STOPS.columns:\n",
    "    if col != 'stop_id':\n",
    "        GTFS_DF_STOPS[f'{col}_len'] = GTFS_DF_STOPS[col].apply(len)\n",
    "\n",
    "# Inspect len columns to find stops with multiple names, suburbs, etc.\n",
    "# GTFS_DF_STOPS[['stop_name_len', 'stop_suburb_len', 'stop_full_name_len', 'stop_lat_len', 'stop_lon_len']].max()\n",
    "        \n",
    "assert GTFS_DF_STOPS['stop_suburb_len'].max() == 1\n",
    "\n",
    "assert GTFS_DF_STOPS.apply(lambda x: x['stop_name_len'] == 1 or (x['stop_lat_len'] == 1 and x['stop_lon_len'] == 1), axis=1).all()\n",
    "\n",
    "GTFS_DF_STOPS['stop_suburb'] = GTFS_DF_STOPS['stop_suburb'].apply(lambda x: x[0])\n",
    "\n",
    "GTFS_DF_STOPS.drop(columns=[col for col in GTFS_DF_STOPS.columns if col.endswith('_len')], inplace=True)\n",
    "\n",
    "GTFS_DF_STOPS = GTFS_DF_STOPS.merge(GTFS_DF_ROUTESTOPS.groupby('stop_id')['route_gtfs_id'].unique().apply(lambda x: ','.join(x)).reset_index(), on='stop_id')\n",
    "\n",
    "GTFS_DF_ROUTES_MIN = GTFS_DF_ROUTES[['route_gtfs_id', 'route_short_name', 'route_long_name', 'mode_id']].drop_duplicates()\n",
    "\n",
    "# # Measure the offset between the multiple latitudes and longitudes values\n",
    "# k = GTFS_DF_STOPS[GTFS_DF_STOPS['stop_lat'].apply(len) > 1]\n",
    "# k['stop_offset_lat'] = k['stop_lat'].apply(lambda x: x[0] - x[1])\n",
    "# k['stop_offset_lon'] = k['stop_lon'].apply(lambda x: x[0] - x[1])\n",
    "# k['stop_offset_lat_m'] = k['stop_offset_lat'].apply(lambda x: np.abs(x * 111139))\n",
    "# k['stop_offset_lon_m'] = k.apply(lambda x: np.abs(x['stop_offset_lon'] * 111139 * np.cos(x['stop_lat'][0])), axis=1)\n",
    "# k.sort_values(['stop_offset_lat_m', 'stop_offset_lon_m'], ascending=False)\n",
    "# GTFS_DF_STOPS[GTFS_DF_STOPS['stop_name'].apply(lambda x: any(['28-Middle St' in i for i in x]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert GTFS_DF_STOPS['stop_suburb'].apply(lambda x: x.count('(') == x.count(')')).all()\n",
    "\n",
    "GTFS_DF_STOPS['stop_suburb_parentheses'] = GTFS_DF_STOPS['stop_suburb'].apply(lambda x: x.count('('))\n",
    "\n",
    "assert (GTFS_DF_STOPS['stop_suburb_parentheses'] <= 1).all()\n",
    "\n",
    "GTFS_DF_STOPS['stop_suburb_name'], GTFS_DF_STOPS['stop_suburb_postcode'] = zip(*GTFS_DF_STOPS['stop_suburb'].apply(lambda x: (x.split('(')[0], x.split('(')[1].removesuffix(')') if '(' in x else np.nan)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, '3081', 'NSW', '3350', 'SA', 'ACT', '3037', '3220', '3219',\n",
       "       'Albury - NSW', '3381'], dtype=object)"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GTFS_DF_STOPS['stop_suburb_postcode'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHP_DIR = '../local/ptv-spatial-datasets'\n",
    "SHP_GDFS : gpd.GeoDataFrame = { f.split('.')[0]: gpd.read_file(os.path.join(SHP_DIR, f)) for f in os.listdir(SHP_DIR) if f.endswith('.shp') }\n",
    "for f in os.listdir(SHP_DIR):\n",
    "    if f.endswith('.txt'):\n",
    "        gdf_name = f.removesuffix('_column_names.txt').upper()\n",
    "        with open(os.path.join(SHP_DIR, f), 'r') as file:\n",
    "            gdf_column_names = [line.strip() for line in file.readlines()][4:]\n",
    "        assert gdf_name in SHP_GDFS, f'{gdf_name} not in GDFS'\n",
    "        for line in gdf_column_names:\n",
    "            assert ' = ' in line, f'Invalid line: {line}'\n",
    "        gdf_column_names = { line.split(' = ')[0]: line.split(' = ')[1] for line in gdf_column_names }\n",
    "        SHP_GDFS[gdf_name].rename(columns=gdf_column_names, inplace=True)\n",
    "\n",
    "assert SHP_GDFS['PTV_METRO_BUS_STOP']['ROUTES_USING_STOP'].notna().all()\n",
    "assert SHP_GDFS['PTV_METRO_TRAM_STOP']['ROUTES_USING_STOP'].notna().all()\n",
    "assert SHP_GDFS['PTV_METRO_TRAIN_STATION']['ROUTES_USING_STOP'].notna().all()\n",
    "# Check if a column exists in a GeoDataFrame\n",
    "assert 'ROUTES_USING_STOP' not in SHP_GDFS['PTV_REGIONAL_COACH_STOP'].columns\n",
    "assert SHP_GDFS['PTV_SKYBUS_STOP']['ROUTES_USING_STOP'].isna().all()\n",
    "assert SHP_GDFS['PTV_REGIONAL_BUS_STOP']['ROUTES_USING_STOP'].notna().any()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "shp_gdf_routes = []\n",
    "for mid, gdf in SHP_GDFS.items():\n",
    "    if 'ROUTE' in mid:\n",
    "        gdf['SHP_FILE'] = mid\n",
    "        shp_gdf_routes.append(gdf)\n",
    "SHP_DF_ROUTES : pd.DataFrame = pd.concat(shp_gdf_routes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\An\\AppData\\Local\\Temp\\ipykernel_25076\\1308935807.py:144: UserWarning: Geometry column does not contain geometry.\n",
      "  SHP_DF_STOPS['geometry'] = SHP_DF_STOPS['geometry'].apply(lambda x: x.coords[0])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "SHP_DF_ROUTES['route_idx'] = SHP_DF_ROUTES['ROUTE_ID'].apply(lambda x: x.split('-'))\n",
    "SHP_DF_ROUTES['route_id0'] = SHP_DF_ROUTES['route_idx'].apply(lambda x: x[0])\n",
    "SHP_DF_ROUTES['route_id1'] = SHP_DF_ROUTES['route_idx'].apply(lambda x: x[1])\n",
    "SHP_DF_ROUTES['route_id2'] = SHP_DF_ROUTES['route_idx'].apply(lambda x: x[2] if len(x) > 4 else np.nan)\n",
    "SHP_DF_ROUTES['route_id3'] = SHP_DF_ROUTES['route_idx'].apply(lambda x: x[-2])\n",
    "SHP_DF_ROUTES['route_id4'] = SHP_DF_ROUTES['route_idx'].apply(lambda x: x[-1])\n",
    "SHP_DF_ROUTES['route_id01'] = SHP_DF_ROUTES['route_id0'] + '-' + SHP_DF_ROUTES['route_id1']\n",
    "\n",
    "assert SHP_DF_ROUTES.groupby('route_id01').aggregate({'route_id2': 'unique', 'route_id3': 'unique', 'route_id4': 'unique'}).apply(lambda x: len(x['route_id2']) <= 1 or len(x['route_id4']) <= 1, axis=1).all()\n",
    "\n",
    "# Since ROUTE_LONG_NAME is all not null, when we merge dataframes, we can use ROUTE_LONG_NAME isna() to check if the other dataframe has the equivalent data in SHP_DF_ROUTES_MIN\n",
    "assert SHP_DF_ROUTES['ROUTE_LONG_NAME'].notna().all()\n",
    "\n",
    "# Inspect the route_id0 values of SHP_DF_ROUTES\n",
    "SHP_DF_ROUTES['route_id0'].sort_values(key=lambda x: x.apply(int)).unique() # array(['3', '4', '5', '6', '7', '11'], dtype=object)\n",
    "\n",
    "# Assert that all metro buses route_short_name are 3 or 4 characters long\n",
    "assert SHP_DF_ROUTES[(SHP_DF_ROUTES['route_id0'] == '4')]['ROUTE_SHORT_NAME'].apply(lambda x: len(x) in [3, 4]).all()\n",
    "# Proof that route_id1 is unique for each ROUTE_SHORT_NAME for route_id0 == 4\n",
    "odd_bus_id1_names = SHP_DF_ROUTES[(SHP_DF_ROUTES['route_id1'] != SHP_DF_ROUTES['ROUTE_SHORT_NAME']) & (SHP_DF_ROUTES['route_id0'] == '4')]['ROUTE_SHORT_NAME'].unique()\n",
    "assert SHP_DF_ROUTES[(SHP_DF_ROUTES['ROUTE_SHORT_NAME'].apply(lambda x: x in odd_bus_id1_names)) & (SHP_DF_ROUTES['route_id0'] == '4')].groupby('ROUTE_SHORT_NAME')['route_id1'].nunique().unique() == [1]\n",
    "\n",
    "def get_gtfs_id(x):\n",
    "    if x['route_id0'] == '4':\n",
    "        return f'4-{x[\"ROUTE_SHORT_NAME\"]}'\n",
    "    elif x['route_id0'] == '7':\n",
    "        assert 'TB' in x[\"route_id1\"], f'7-TeleBus route_id1 {x[\"route_id1\"]} does not contain TB'\n",
    "        route_number = x[\"route_id1\"].lstrip('TB')\n",
    "        # Add left trailing 0s\n",
    "        route_number = route_number.zfill(2)\n",
    "        return f'7-B{route_number}'\n",
    "    else:\n",
    "        return f'{x[\"route_id0\"]}-{x[\"route_id1\"]}'\n",
    "\n",
    "SHP_DF_ROUTES['route_shp_id'] = SHP_DF_ROUTES.apply(lambda x: f'{x[\"route_id0\"]}-{x[\"route_id1\"]}' + (x['route_id2'] if x['route_id0'] == '4' and pd.notna(x['route_id2']) else ''), axis=1)\n",
    "SHP_DF_ROUTES['route_gtfs_id'] = SHP_DF_ROUTES.apply(lambda x: get_gtfs_id(x), axis=1)\n",
    "\n",
    "SHP_DF_ROUTES_MIN = SHP_DF_ROUTES[['route_gtfs_id', 'route_shp_id', 'route_id0', 'ROUTE_SHORT_NAME', 'ROUTE_LONG_NAME', 'SHP_FILE']].drop_duplicates()\n",
    "\n",
    "SHP_DF_ROUTES_MIN = SHP_DF_ROUTES_MIN.groupby('route_gtfs_id').aggregate({'route_shp_id': 'unique', 'route_id0': 'unique', 'ROUTE_SHORT_NAME': 'unique', 'ROUTE_LONG_NAME': 'unique', 'SHP_FILE': 'unique'}).reset_index()\n",
    "\n",
    "assert SHP_DF_ROUTES_MIN['route_shp_id'].apply(lambda x: len(x) == 1).all()\n",
    "assert SHP_DF_ROUTES_MIN['route_id0'].apply(lambda x: len(x) == 1).all()\n",
    "assert SHP_DF_ROUTES_MIN['ROUTE_SHORT_NAME'].apply(lambda x: len(x) == 1).all()\n",
    "assert SHP_DF_ROUTES_MIN['SHP_FILE'].apply(lambda x: len(x) == 1).all()\n",
    "\n",
    "# Inspect multiple ROUTE_LONG_NAME of the same route_gtfs_id\n",
    "SHP_DF_ROUTES_MIN[SHP_DF_ROUTES_MIN['ROUTE_LONG_NAME'].apply(lambda x: len(x) != 1)]\n",
    "\n",
    "SHP_DF_ROUTES_MIN['route_shp_id'] = SHP_DF_ROUTES_MIN['route_shp_id'].apply(lambda x: x[0])\n",
    "SHP_DF_ROUTES_MIN['route_id0'] = SHP_DF_ROUTES_MIN['route_id0'].apply(lambda x: x[0])\n",
    "SHP_DF_ROUTES_MIN['ROUTE_SHORT_NAME'] = SHP_DF_ROUTES_MIN['ROUTE_SHORT_NAME'].apply(lambda x: x[0])\n",
    "SHP_DF_ROUTES_MIN['SHP_FILE'] = SHP_DF_ROUTES_MIN['SHP_FILE'].apply(lambda x: x[0])\n",
    "\n",
    "# Inspect SHP_FILE and route_id0\n",
    "SHP_DF_ROUTES_MIN[['SHP_FILE', 'route_id0']].drop_duplicates().sort_values('SHP_FILE')\n",
    "\n",
    "\n",
    "assert SHP_GDFS['PTV_METRO_TRAM_STOP']['STOP_ID'].is_unique\n",
    "assert SHP_GDFS['PTV_METRO_TRAIN_STATION']['STOP_ID'].is_unique\n",
    "assert SHP_GDFS['PTV_REGIONAL_BUS_STOP']['STOP_ID'].is_unique\n",
    "assert SHP_GDFS['PTV_REGIONAL_COACH_STOP']['STOP_ID'].is_unique\n",
    "assert SHP_GDFS['PTV_SKYBUS_STOP']['STOP_ID'].is_unique\n",
    "\n",
    "# STOP ID in PTV_METRO_BUS_STOP is not unique, however it's only because of the addition of TeleBus routes\n",
    "shp_metro_bus_stop_duplicated_ids = SHP_GDFS['PTV_METRO_BUS_STOP'][SHP_GDFS['PTV_METRO_BUS_STOP']['STOP_ID'].duplicated(keep=False)].groupby('STOP_ID')['ROUTES_USING_STOP'].unique()\n",
    "assert shp_metro_bus_stop_duplicated_ids.apply(lambda x: len(x) == 2).all()\n",
    "assert shp_metro_bus_stop_duplicated_ids.apply(lambda x: len([i for i in x if 'TeleBus' in i]) == 1).all()\n",
    "\n",
    "# Split PTV_METRO_BUS_STOP into PTV_METROBUS_STOP and PTV_TELEBUS_STOP\n",
    "SHP_GDFS['PTV_METROBUS_STOP'] = SHP_GDFS['PTV_METRO_BUS_STOP'][SHP_GDFS['PTV_METRO_BUS_STOP']['ROUTES_USING_STOP'].apply(lambda x: 'TeleBus' not in x)].reset_index(drop=True)\n",
    "SHP_GDFS['PTV_TELEBUS_STOP'] = SHP_GDFS['PTV_METRO_BUS_STOP'][SHP_GDFS['PTV_METRO_BUS_STOP']['ROUTES_USING_STOP'].apply(lambda x: 'TeleBus' in x)].reset_index(drop=True)\n",
    "\n",
    "assert SHP_GDFS['PTV_METROBUS_STOP']['STOP_ID'].is_unique\n",
    "assert SHP_GDFS['PTV_TELEBUS_STOP']['STOP_ID'].is_unique\n",
    "\n",
    "SHP_DFS_STOPS = {\n",
    "    '2': SHP_GDFS['PTV_METRO_TRAIN_STATION'],\n",
    "    '3': SHP_GDFS['PTV_METRO_TRAM_STOP'],\n",
    "    '4': SHP_GDFS['PTV_METROBUS_STOP'],\n",
    "    # '5': SHP_GDFS['PTV_REGIONAL_COACH_STOP'],\n",
    "    '6': SHP_GDFS['PTV_REGIONAL_BUS_STOP'],\n",
    "    '7': SHP_GDFS['PTV_TELEBUS_STOP'],\n",
    "    '11': SHP_GDFS['PTV_SKYBUS_STOP']\n",
    "}\n",
    "\n",
    "for mid in SHP_DFS_STOPS:\n",
    "    SHP_DFS_STOPS[mid]['ROUTE'] = SHP_DFS_STOPS[mid]['ROUTES_USING_STOP'].apply(lambda x: x.split(',') if pd.notna(x) else [])\n",
    "    SHP_DFS_STOPS[mid] = SHP_DFS_STOPS[mid][['STOP_ID', 'ROUTE']].explode('ROUTE').reset_index(drop=True)\n",
    "\n",
    "for mid in ['3', '4', '6', '7', '11']:\n",
    "    SHP_DFS_STOPS[mid] = SHP_DFS_STOPS[mid].merge(SHP_DF_ROUTES_MIN[SHP_DF_ROUTES_MIN['route_id0'] == mid], left_on='ROUTE', right_on='ROUTE_SHORT_NAME', how='left')\n",
    "        \n",
    "\n",
    "# Assert that there is no odd ROUTE in SHP_DFS_STOPS\n",
    "assert SHP_DFS_STOPS['3']['ROUTE_SHORT_NAME'].notna().all()\n",
    "assert SHP_DFS_STOPS['4']['ROUTE_SHORT_NAME'].notna().all()\n",
    "assert SHP_DFS_STOPS['7']['ROUTE_SHORT_NAME'].notna().all()\n",
    "# assert 'ROUTE' not in SHP_DFS_STOPS['5'].columns\n",
    "assert (SHP_DFS_STOPS['6'][SHP_DFS_STOPS['6']['ROUTE'].notna() & SHP_DFS_STOPS['6']['ROUTE_SHORT_NAME'].isna()]['ROUTE'] == '').all()\n",
    "assert (SHP_DFS_STOPS['11'][SHP_DFS_STOPS['11']['ROUTE'].notna() & SHP_DFS_STOPS['11']['ROUTE_SHORT_NAME'].isna()]['ROUTE'] == '').all()\n",
    "\n",
    "\n",
    "gtfs_df_routes_metrotrains = GTFS_DF_ROUTES_MIN[GTFS_DF_ROUTES_MIN['mode_id'] == '2'][['route_gtfs_id', 'route_short_name']].drop_duplicates().sort_values('route_short_name')\n",
    "\n",
    "SHP_DFS_STOPS['2'] = SHP_DFS_STOPS['2'][['STOP_ID', 'ROUTE']].drop_duplicates()\n",
    "SHP_DFS_STOPS['2'] = pd.merge(SHP_DFS_STOPS['2'], gtfs_df_routes_metrotrains, left_on='ROUTE', right_on='route_short_name', how='left')\n",
    "assert SHP_DFS_STOPS['2']['route_gtfs_id'].notna().all()\n",
    "\n",
    "for mid in ['2', '3', '4', '6', '7', '11']:\n",
    "    SHP_DFS_STOPS[mid] = SHP_DFS_STOPS[mid].dropna(subset=['ROUTE'])\n",
    "    SHP_DFS_STOPS[mid]['route_gtfs_id'] = SHP_DFS_STOPS[mid].apply(lambda x: x['route_gtfs_id'] if pd.notna(x['route_gtfs_id']) else x['ROUTE'], axis=1)\n",
    "    SHP_DFS_STOPS[mid] = SHP_DFS_STOPS[mid].groupby('STOP_ID').aggregate({'ROUTE': 'unique', 'route_gtfs_id': 'unique'}).reset_index()\n",
    "    SHP_DFS_STOPS[mid]['ROUTE'] = SHP_DFS_STOPS[mid]['ROUTE'].apply(lambda x: ','.join(x))\n",
    "    SHP_DFS_STOPS[mid]['route_gtfs_id'] = SHP_DFS_STOPS[mid]['route_gtfs_id'].apply(lambda x: ','.join(x))\n",
    "\n",
    "\n",
    "SHP_GDFS['PTV_METRO_TRAIN_STATION'] = pd.merge(SHP_GDFS['PTV_METRO_TRAIN_STATION'], SHP_DFS_STOPS['2'][['STOP_ID', 'route_gtfs_id']], on='STOP_ID', how='left')\n",
    "SHP_GDFS['PTV_METRO_TRAM_STOP'] = pd.merge(SHP_GDFS['PTV_METRO_TRAM_STOP'], SHP_DFS_STOPS['3'][['STOP_ID', 'route_gtfs_id']], on='STOP_ID', how='left')\n",
    "SHP_GDFS['PTV_METROBUS_STOP'] = pd.merge(SHP_GDFS['PTV_METROBUS_STOP'], SHP_DFS_STOPS['4'][['STOP_ID', 'route_gtfs_id']], on='STOP_ID', how='left')\n",
    "SHP_GDFS['PTV_REGIONAL_BUS_STOP'] = pd.merge(SHP_GDFS['PTV_REGIONAL_BUS_STOP'], SHP_DFS_STOPS['6'][['STOP_ID', 'route_gtfs_id']], on='STOP_ID', how='left')\n",
    "SHP_GDFS['PTV_TELEBUS_STOP'] = pd.merge(SHP_GDFS['PTV_TELEBUS_STOP'], SHP_DFS_STOPS['7'][['STOP_ID', 'route_gtfs_id']], on='STOP_ID', how='left')\n",
    "SHP_GDFS['PTV_SKYBUS_STOP'] = pd.merge(SHP_GDFS['PTV_SKYBUS_STOP'], SHP_DFS_STOPS['11'][['STOP_ID', 'route_gtfs_id']], on='STOP_ID', how='left')\n",
    "\n",
    "\n",
    "SHP_GDFS['PTV_METRO_TRAIN_STATION']['mode_id'] = '2'\n",
    "SHP_GDFS['PTV_METRO_TRAM_STOP']['mode_id'] = '3'\n",
    "SHP_GDFS['PTV_METROBUS_STOP']['mode_id'] = '4'\n",
    "SHP_GDFS['PTV_REGIONAL_COACH_STOP']['mode_id'] = '5'\n",
    "SHP_GDFS['PTV_REGIONAL_BUS_STOP']['mode_id'] = '6'\n",
    "SHP_GDFS['PTV_TELEBUS_STOP']['mode_id'] = '7'\n",
    "SHP_GDFS['PTV_SKYBUS_STOP']['mode_id'] = '11'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\An\\AppData\\Local\\Temp\\ipykernel_25076\\2106786907.py:11: UserWarning: Geometry column does not contain geometry.\n",
      "  SHP_DF_STOPS['geometry'] = SHP_DF_STOPS['geometry'].apply(lambda x: x.coords[0])\n"
     ]
    }
   ],
   "source": [
    "SHP_DF_STOPS : pd.DataFrame = pd.concat([\n",
    "    SHP_GDFS['PTV_METRO_TRAIN_STATION'],\n",
    "    SHP_GDFS['PTV_METRO_TRAM_STOP'],\n",
    "    SHP_GDFS['PTV_METROBUS_STOP'],\n",
    "    SHP_GDFS['PTV_REGIONAL_COACH_STOP'],\n",
    "    SHP_GDFS['PTV_REGIONAL_BUS_STOP'],\n",
    "    SHP_GDFS['PTV_TELEBUS_STOP'],\n",
    "    SHP_GDFS['PTV_SKYBUS_STOP']\n",
    "])\n",
    "\n",
    "SHP_DF_STOPS['geometry'] = SHP_DF_STOPS['geometry'].apply(lambda x: x.coords[0])\n",
    "SHP_DF_STOPS['STOP_FULL_NAME'] = SHP_DF_STOPS['STOP_NAME']\n",
    "\n",
    "\n",
    "# Count occurrences of '(' and ')' in STOP_FULL_NAME\n",
    "assert SHP_DF_STOPS['STOP_FULL_NAME'].apply(lambda x: x.count('(') == x.count(')')).all()\n",
    "SHP_DF_STOPS['parentheses_count'] = SHP_DF_STOPS['STOP_FULL_NAME'].apply(lambda x: x.count('('))\n",
    "SHP_DF_STOPS[SHP_DF_STOPS['parentheses_count'] != 1]\n",
    "SHP_DF_STOPS.drop(columns='parentheses_count', inplace=True)\n",
    "\n",
    "# Get only the last pair of parentheses\n",
    "def get_suburb(stop_full_name):\n",
    "    if '(' not in stop_full_name:\n",
    "        stop_name = stop_full_name\n",
    "        stop_suburb = np.nan\n",
    "        return (stop_name, stop_suburb)\n",
    "    parentheses_count = 0\n",
    "    for i in range(len(stop_full_name) - 1, -1, -1):\n",
    "        c = stop_full_name[i]\n",
    "        if c == ')':\n",
    "            parentheses_count += 1\n",
    "        if c == '(':\n",
    "            parentheses_count -= 1\n",
    "        if parentheses_count == 0:\n",
    "            stop_name = stop_full_name[:i].strip()\n",
    "            stop_suburb = stop_full_name[i:].removesuffix(')').lstrip('(')\n",
    "            return (stop_name, stop_suburb)\n",
    "\n",
    "SHP_DF_STOPS['STOP_SUBURB'] = SHP_DF_STOPS['STOP_FULL_NAME'].apply(get_suburb)\n",
    "SHP_DF_STOPS['STOP_NAME'] = SHP_DF_STOPS['STOP_SUBURB'].apply(lambda x: x[0])\n",
    "SHP_DF_STOPS['STOP_SUBURB'] = SHP_DF_STOPS['STOP_SUBURB'].apply(lambda x: x[1])\n",
    "\n",
    "\n",
    "# Inspection of the data shows that there are some stops with no suburb. We will manually fill these in.\n",
    "SHP_DF_STOPS[SHP_DF_STOPS['STOP_SUBURB'].isna()]\n",
    "\n",
    "def custom_stop_suburb(x):\n",
    "    if x['STOP_ID'] == '35117':\n",
    "        assert x['STOP_NAME'] == 'Ascot St/Sturt St', x['STOP_NAME']\n",
    "        return 'Ballarat Central'\n",
    "    return x['STOP_SUBURB']\n",
    "\n",
    "SHP_DF_STOPS['STOP_SUBURB'] = SHP_DF_STOPS.apply(custom_stop_suburb, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert SHP_DF_STOPS['STOP_SUBURB'].apply(lambda x: x.count('(') == x.count(')')).all()\n",
    "\n",
    "SHP_DF_STOPS['STOP_SUBURB_PARENTHESES'] = SHP_DF_STOPS['STOP_SUBURB'].apply(lambda x: x.count('('))\n",
    "\n",
    "assert (SHP_DF_STOPS['STOP_SUBURB_PARENTHESES'] <= 1).all()\n",
    "\n",
    "SHP_DF_STOPS['STOP_SUBURB_NAME'], SHP_DF_STOPS['STOP_SUBURB_POSTCODE'] = zip(*SHP_DF_STOPS['STOP_SUBURB'].apply(lambda x: (x.split('(')[0], x.split('(')[1].removesuffix(')') if '(' in x else np.nan)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, '3081', '3037', '3381', '3350', 'NSW', '3220', '3219', 'SA',\n",
       "       'Albury - NSW'], dtype=object)"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SHP_DF_STOPS['STOP_SUBURB_POSTCODE'].unique()\n",
    "\n",
    "# array([nan, '3081', '3037', '3381', '3350', 'NSW', '3220', '3219', 'SA', 'Albury - NSW'], dtype=object)\n",
    "\n",
    "# array([nan, '3081', 'NSW', '3350', 'SA', 'ACT', '3037', '3220', '3219', 'Albury - NSW', '3381'], dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SHP_DF_STOPS['LATITUDE'] = SHP_DF_STOPS['LATITUDE'].apply(np.float64)\n",
    "SHP_DF_STOPS['LONGITUDE'] = SHP_DF_STOPS['LONGITUDE'].apply(np.float64)\n",
    "\n",
    "\n",
    "SHP_DF_STOPS = SHP_DF_STOPS.groupby('STOP_ID').aggregate({'STOP_NAME': 'unique', 'STOP_SUBURB': 'unique', 'STOP_FULL_NAME': 'unique', 'LATITUDE': 'unique', 'LONGITUDE': 'unique', 'TICKETZONE': 'unique', 'route_gtfs_id': 'unique', 'geometry': 'unique'})\n",
    "# 7s - 10s\n",
    "SHP_DF_STOPS.reset_index(inplace=True)\n",
    "\n",
    "for col in SHP_DF_STOPS.columns:\n",
    "    if col != 'STOP_ID':\n",
    "        SHP_DF_STOPS[f'{col}_len'] = SHP_DF_STOPS[col].apply(len)\n",
    "\n",
    "for col in ['STOP_NAME', 'STOP_SUBURB', 'STOP_FULL_NAME', 'LATITUDE', 'LONGITUDE', 'geometry']:\n",
    "    assert SHP_DF_STOPS[f'{col}_len'].max() == 1\n",
    "    SHP_DF_STOPS[col] = SHP_DF_STOPS[col].apply(lambda x: x[0])\n",
    "\n",
    "SHP_DF_STOPS['TICKETZONE'] = SHP_DF_STOPS['TICKETZONE'].apply(lambda x: ','.join([str(i) for i in x if not pd.isna(i)]))\n",
    "SHP_DF_STOPS['route_gtfs_id'] = SHP_DF_STOPS['route_gtfs_id'].apply(lambda x: ','.join([str(i) for i in x if not pd.isna(i)]))\n",
    "\n",
    "SHP_DF_STOPS.drop(columns=[col for col in SHP_DF_STOPS.columns if col.endswith('_len')], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "GS_DF_STOPS = pd.merge(GTFS_DF_STOPS, SHP_DF_STOPS, left_on='stop_id', right_on='STOP_ID', suffixes=('_gtfs', '_shp'), how='outer')\n",
    "\n",
    "GS_DF_STOPS.drop(columns=['stop_full_name', 'STOP_FULL_NAME'], inplace=True)\n",
    "\n",
    "# Assert that all GTFS stops with multiple names have an equivalent in SHP\n",
    "assert GS_DF_STOPS[GS_DF_STOPS['stop_name'].apply(lambda x: isinstance(x, np.ndarray) and len(x) > 1)]['STOP_ID'].notna().all()\n",
    "\n",
    "# Assert that all GTFS stops with multiple names have an equivalent in SHP, and the equivalent's name is among the multiple names\n",
    "assert GS_DF_STOPS[GS_DF_STOPS['STOP_ID'].notna() & GS_DF_STOPS['stop_id'].notna()].apply(lambda x: x['STOP_NAME'] in x['stop_name'] if len(x['stop_name']) > 1 else True, axis=1).all()\n",
    "\n",
    "# Choose the name from SHP if it is in the GTFS stop_name, else choose the GTFS stop_name. It is guaranteed that when we choose x['stop_name'][0], the x['stop_name'] only has one element.\n",
    "GS_DF_STOPS['stop_name'] = GS_DF_STOPS.apply(lambda x: (x['STOP_NAME'] if (x['STOP_NAME'] in x['stop_name']) else x['stop_name'][0]) if isinstance(x['stop_name'], np.ndarray) else x['stop_name'], axis=1)\n",
    "\n",
    "# Assert that all GTFS stops with multiple latitudes and longitudes have an equivalent in SHP\n",
    "assert GS_DF_STOPS[GS_DF_STOPS['stop_lat'].apply(lambda x: isinstance(x, np.ndarray) and len(x) > 1)]['LATITUDE'].notna().all()\n",
    "\n",
    "# Assert that all GTFS stops with multiple latitudes and longitudes have an equivalent in SHP\n",
    "assert GS_DF_STOPS[GS_DF_STOPS['stop_lon'].apply(lambda x: isinstance(x, np.ndarray) and len(x) > 1)]['LONGITUDE'].notna().all()\n",
    "\n",
    "# # Latitude and longitude are completely different between GTFS and SHP\n",
    "# k = GS_DF_STOPS[GS_DF_STOPS['LATITUDE'].notna() & GS_DF_STOPS['stop_lat'].notna()]\n",
    "# len(k[k.apply(lambda x: x['geometry'][0] == x['stop_lat'][1] if len(x['stop_lat']) > 1 else False, axis=1)])\n",
    "\n",
    "# assert GS_DF_STOPS[GS_DF_STOPS['LONGITUDE'].notna() & GS_DF_STOPS['stop_lon'].notna()].apply(lambda x: x['LONGITUDE'] in x['stop_lon'] if len(x['stop_lon']) > 1 else True, axis=1).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "GS_DF_STOPS_FULL = GS_DF_STOPS[GS_DF_STOPS['stop_id'].notna() & GS_DF_STOPS['STOP_ID'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stop_id</th>\n",
       "      <th>stop_name</th>\n",
       "      <th>stop_suburb</th>\n",
       "      <th>stop_lat</th>\n",
       "      <th>stop_lon</th>\n",
       "      <th>route_gtfs_id_gtfs</th>\n",
       "      <th>STOP_ID</th>\n",
       "      <th>STOP_NAME</th>\n",
       "      <th>STOP_SUBURB</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>TICKETZONE</th>\n",
       "      <th>route_gtfs_id_shp</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>11380</td>\n",
       "      <td>Navan Park/Opp 284 Coburns Rd</td>\n",
       "      <td>Melton</td>\n",
       "      <td>[-37.6716077893165]</td>\n",
       "      <td>[144.570689039386]</td>\n",
       "      <td>4-453</td>\n",
       "      <td>11380</td>\n",
       "      <td>Navan Park/Coburns Rd</td>\n",
       "      <td>Harkness</td>\n",
       "      <td>-37.671608</td>\n",
       "      <td>144.570689</td>\n",
       "      <td>2</td>\n",
       "      <td>4-453</td>\n",
       "      <td>(144.5706949696913, -37.671594795876835)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2645</th>\n",
       "      <td>13005</td>\n",
       "      <td>Tucker Rd/Mawby Rd</td>\n",
       "      <td>Bentleigh</td>\n",
       "      <td>[-37.9288844259794]</td>\n",
       "      <td>[145.051446659906]</td>\n",
       "      <td>4-701</td>\n",
       "      <td>13005</td>\n",
       "      <td>Corolla Ave/Mawby Rd</td>\n",
       "      <td>Bentleigh East</td>\n",
       "      <td>-37.928884</td>\n",
       "      <td>145.051447</td>\n",
       "      <td>2</td>\n",
       "      <td>4-701</td>\n",
       "      <td>(145.05145288116285, -37.9288708135009)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2893</th>\n",
       "      <td>13273</td>\n",
       "      <td>Tucker Rd/Mawby Rd</td>\n",
       "      <td>Bentleigh</td>\n",
       "      <td>[-37.9289745038198]</td>\n",
       "      <td>[145.05144428165]</td>\n",
       "      <td>4-701</td>\n",
       "      <td>13273</td>\n",
       "      <td>Corolla Ave/Mawby Rd</td>\n",
       "      <td>Bentleigh East</td>\n",
       "      <td>-37.928975</td>\n",
       "      <td>145.051444</td>\n",
       "      <td>2</td>\n",
       "      <td>4-701</td>\n",
       "      <td>(145.05145000127632, -37.928961893472824)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10861</th>\n",
       "      <td>23370</td>\n",
       "      <td>Cana Catholic Primary School/Banchory Ave</td>\n",
       "      <td>Hillside</td>\n",
       "      <td>[-37.6886506993103]</td>\n",
       "      <td>[144.746362690131]</td>\n",
       "      <td>4-460</td>\n",
       "      <td>23370</td>\n",
       "      <td>Cana Catholic PS/Banchory Ave</td>\n",
       "      <td>Hillside (3037)</td>\n",
       "      <td>-37.688651</td>\n",
       "      <td>144.746363</td>\n",
       "      <td>2</td>\n",
       "      <td>4-460</td>\n",
       "      <td>(144.74636917731445, -37.68863783016752)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10862</th>\n",
       "      <td>23371</td>\n",
       "      <td>Cana Catholic Primary School/Banchory Ave</td>\n",
       "      <td>Hillside</td>\n",
       "      <td>[-37.6887205834372]</td>\n",
       "      <td>[144.746247175734]</td>\n",
       "      <td>4-460</td>\n",
       "      <td>23371</td>\n",
       "      <td>Cana Catholic PS/Banchory Ave</td>\n",
       "      <td>Hillside (3037)</td>\n",
       "      <td>-37.688721</td>\n",
       "      <td>144.746247</td>\n",
       "      <td>2</td>\n",
       "      <td>4-460</td>\n",
       "      <td>(144.7462528974455, -37.68870785016954)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18992</th>\n",
       "      <td>44354</td>\n",
       "      <td>Silverbush Way/Sayers Rd</td>\n",
       "      <td>Williams Landing</td>\n",
       "      <td>[-37.8526725083357]</td>\n",
       "      <td>[144.730136572865]</td>\n",
       "      <td>4-150,4-151</td>\n",
       "      <td>44354</td>\n",
       "      <td>Forsyth Rd/Sayers Rd</td>\n",
       "      <td>Truganina</td>\n",
       "      <td>-37.852673</td>\n",
       "      <td>144.730137</td>\n",
       "      <td>2</td>\n",
       "      <td>4-151,4-150</td>\n",
       "      <td>(144.73014288010182, -37.85265986607712)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20582</th>\n",
       "      <td>46758</td>\n",
       "      <td>Hillside Recreation Reserve/Royal Cres</td>\n",
       "      <td>Hillside</td>\n",
       "      <td>[-37.6855406909971]</td>\n",
       "      <td>[144.739721256821]</td>\n",
       "      <td>4-463</td>\n",
       "      <td>46758</td>\n",
       "      <td>Hillside Rec Reserve/Royal Cres</td>\n",
       "      <td>Hillside (3037)</td>\n",
       "      <td>-37.685541</td>\n",
       "      <td>144.739721</td>\n",
       "      <td>2</td>\n",
       "      <td>4-463</td>\n",
       "      <td>(144.739727179593, -37.68552779019742)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24321</th>\n",
       "      <td>5540</td>\n",
       "      <td>Bulleen Terminus/Thompsons Rd</td>\n",
       "      <td>Bulleen</td>\n",
       "      <td>[-37.7698542902203]</td>\n",
       "      <td>[145.10009803421]</td>\n",
       "      <td>4-905</td>\n",
       "      <td>5540</td>\n",
       "      <td>Manningham Rd/Thompsons Rd</td>\n",
       "      <td>Templestowe Lower</td>\n",
       "      <td>-37.769854</td>\n",
       "      <td>145.100098</td>\n",
       "      <td>2</td>\n",
       "      <td>4-905</td>\n",
       "      <td>(145.10010398045483, -37.76984080991194)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      stop_id                                  stop_name       stop_suburb  \\\n",
       "1218    11380              Navan Park/Opp 284 Coburns Rd            Melton   \n",
       "2645    13005                         Tucker Rd/Mawby Rd         Bentleigh   \n",
       "2893    13273                         Tucker Rd/Mawby Rd         Bentleigh   \n",
       "10861   23370  Cana Catholic Primary School/Banchory Ave          Hillside   \n",
       "10862   23371  Cana Catholic Primary School/Banchory Ave          Hillside   \n",
       "18992   44354                   Silverbush Way/Sayers Rd  Williams Landing   \n",
       "20582   46758     Hillside Recreation Reserve/Royal Cres          Hillside   \n",
       "24321    5540              Bulleen Terminus/Thompsons Rd           Bulleen   \n",
       "\n",
       "                  stop_lat            stop_lon route_gtfs_id_gtfs STOP_ID  \\\n",
       "1218   [-37.6716077893165]  [144.570689039386]              4-453   11380   \n",
       "2645   [-37.9288844259794]  [145.051446659906]              4-701   13005   \n",
       "2893   [-37.9289745038198]   [145.05144428165]              4-701   13273   \n",
       "10861  [-37.6886506993103]  [144.746362690131]              4-460   23370   \n",
       "10862  [-37.6887205834372]  [144.746247175734]              4-460   23371   \n",
       "18992  [-37.8526725083357]  [144.730136572865]        4-150,4-151   44354   \n",
       "20582  [-37.6855406909971]  [144.739721256821]              4-463   46758   \n",
       "24321  [-37.7698542902203]   [145.10009803421]              4-905    5540   \n",
       "\n",
       "                             STOP_NAME        STOP_SUBURB   LATITUDE  \\\n",
       "1218             Navan Park/Coburns Rd           Harkness -37.671608   \n",
       "2645              Corolla Ave/Mawby Rd     Bentleigh East -37.928884   \n",
       "2893              Corolla Ave/Mawby Rd     Bentleigh East -37.928975   \n",
       "10861    Cana Catholic PS/Banchory Ave    Hillside (3037) -37.688651   \n",
       "10862    Cana Catholic PS/Banchory Ave    Hillside (3037) -37.688721   \n",
       "18992             Forsyth Rd/Sayers Rd          Truganina -37.852673   \n",
       "20582  Hillside Rec Reserve/Royal Cres    Hillside (3037) -37.685541   \n",
       "24321       Manningham Rd/Thompsons Rd  Templestowe Lower -37.769854   \n",
       "\n",
       "        LONGITUDE TICKETZONE route_gtfs_id_shp  \\\n",
       "1218   144.570689          2             4-453   \n",
       "2645   145.051447          2             4-701   \n",
       "2893   145.051444          2             4-701   \n",
       "10861  144.746363          2             4-460   \n",
       "10862  144.746247          2             4-460   \n",
       "18992  144.730137          2       4-151,4-150   \n",
       "20582  144.739721          2             4-463   \n",
       "24321  145.100098          2             4-905   \n",
       "\n",
       "                                        geometry  \n",
       "1218    (144.5706949696913, -37.671594795876835)  \n",
       "2645     (145.05145288116285, -37.9288708135009)  \n",
       "2893   (145.05145000127632, -37.928961893472824)  \n",
       "10861   (144.74636917731445, -37.68863783016752)  \n",
       "10862    (144.7462528974455, -37.68870785016954)  \n",
       "18992   (144.73014288010182, -37.85265986607712)  \n",
       "20582     (144.739727179593, -37.68552779019742)  \n",
       "24321   (145.10010398045483, -37.76984080991194)  "
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GS_DF_STOPS_FULL[GS_DF_STOPS_FULL['stop_suburb'] != GS_DF_STOPS_FULL['STOP_SUBURB']]\n",
    "# GS_DF_STOPS_FULL[GS_DF_STOPS_FULL['stop_name'] != GS_DF_STOPS_FULL['STOP_NAME']]\n",
    "GS_DF_STOPS_FULL[(GS_DF_STOPS_FULL['stop_name'] != GS_DF_STOPS_FULL['STOP_NAME']) & (GS_DF_STOPS_FULL['stop_suburb'] != GS_DF_STOPS_FULL['STOP_SUBURB'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stop_id</th>\n",
       "      <th>stop_name</th>\n",
       "      <th>stop_suburb</th>\n",
       "      <th>stop_lat</th>\n",
       "      <th>stop_lon</th>\n",
       "      <th>route_gtfs_id_gtfs</th>\n",
       "      <th>STOP_ID</th>\n",
       "      <th>STOP_NAME</th>\n",
       "      <th>STOP_SUBURB</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>TICKETZONE</th>\n",
       "      <th>route_gtfs_id_shp</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24373</th>\n",
       "      <td>5588</td>\n",
       "      <td>Rosemary St/High St</td>\n",
       "      <td>Templestowe Lower</td>\n",
       "      <td>[-37.7604947207492]</td>\n",
       "      <td>[145.118874510881]</td>\n",
       "      <td>4-309,4-281</td>\n",
       "      <td>5588</td>\n",
       "      <td>MacRobertson St/High St</td>\n",
       "      <td>Templestowe Lower</td>\n",
       "      <td>-37.760495</td>\n",
       "      <td>145.118875</td>\n",
       "      <td>2</td>\n",
       "      <td>4-309,4-281</td>\n",
       "      <td>(145.11888087300423, -37.76048189116718)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      stop_id            stop_name        stop_suburb             stop_lat  \\\n",
       "24373    5588  Rosemary St/High St  Templestowe Lower  [-37.7604947207492]   \n",
       "\n",
       "                 stop_lon route_gtfs_id_gtfs STOP_ID                STOP_NAME  \\\n",
       "24373  [145.118874510881]        4-309,4-281    5588  MacRobertson St/High St   \n",
       "\n",
       "             STOP_SUBURB   LATITUDE   LONGITUDE TICKETZONE route_gtfs_id_shp  \\\n",
       "24373  Templestowe Lower -37.760495  145.118875          2       4-309,4-281   \n",
       "\n",
       "                                       geometry  \n",
       "24373  (145.11888087300423, -37.76048189116718)  "
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GS_DF_STOPS_FULL[GS_DF_STOPS_FULL['stop_id'] == '5588']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "GS_DF_STOPS_MISSING = GS_DF_STOPS[GS_DF_STOPS['stop_id'].isna() | GS_DF_STOPS['STOP_ID'].isna()].copy()\n",
    "GS_DF_STOPS_MISSING['union_stop_name'] = GS_DF_STOPS_MISSING.apply(lambda x: x['stop_name'] if pd.isna(x['STOP_ID']) else x['STOP_NAME'], axis=1)\n",
    "GS_DF_STOPS_MISSING['union_stop_suburb'] = GS_DF_STOPS_MISSING.apply(lambda x: x['stop_suburb'] if pd.isna(x['STOP_ID']) else x['STOP_SUBURB'], axis=1)\n",
    "GS_DF_STOPS_MISSING.sort_values(['union_stop_name', 'union_stop_suburb'], inplace=True)\n",
    "# Wrap in \" \"\n",
    "GS_DF_STOPS_MISSING.to_csv('../local/gs-stop-missing.csv', index=False, quoting=csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtfs_custom_stopid_check = [\"49276\",\"49278\",\"49275\",\"49279\",\"49280\",\"28205\",\"22251\",\"28341\",\"28342\",\"28343\",\"28344\",\"28345\",\"28346\",\"28347\",\"28348\",\"27745\",\"27746\",\"27747\",\"48879\",\"22694\",\"28165\",\"28166\",\"28167\",\"17245\",\"48471\",\"48474\",\"49602\",\"49605\",\"49468\",\"28537\",\"28538\",\"28539\",\"28540\",\"28541\",\"28542\",\"28543\"]\n",
    "shp_custom_stopid_check = [\"18074\",\"18558\",\"18082\",\"18561\",\"18562\",\"40072\",\"48382\",\"27882\",\"2507\",\"3348\",\"41652\",\"18859\",\"18860\",\"18861\",\"44707\",\"19806\",\"19808\",\"37491\",\"37475\",\"8637\",\"27985\",\"27986\",\"50255\",\"50256\",\"50257\",\"50258\",\"50259\",\"50260\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stop_id</th>\n",
       "      <th>stop_name</th>\n",
       "      <th>stop_suburb</th>\n",
       "      <th>stop_lat</th>\n",
       "      <th>stop_lon</th>\n",
       "      <th>STOP_ID</th>\n",
       "      <th>STOP_NAME</th>\n",
       "      <th>STOP_SUBURB</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>TICKETZONE</th>\n",
       "      <th>ROUTES_USING_STOP</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6692</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18074</td>\n",
       "      <td>33-South Daly St/Dawson St</td>\n",
       "      <td>Brunswick West</td>\n",
       "      <td>-37.769399</td>\n",
       "      <td>144.944169</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>(144.94417509159285, -37.76938584520886)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22221</th>\n",
       "      <td>49276</td>\n",
       "      <td>33-South Daly St/Dawson St</td>\n",
       "      <td>Brunswick West</td>\n",
       "      <td>[-37.7695279063077]</td>\n",
       "      <td>[144.945357459904]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      stop_id                   stop_name     stop_suburb  \\\n",
       "6692      NaN                         NaN             NaN   \n",
       "22221   49276  33-South Daly St/Dawson St  Brunswick West   \n",
       "\n",
       "                  stop_lat            stop_lon STOP_ID  \\\n",
       "6692                   NaN                 NaN   18074   \n",
       "22221  [-37.7695279063077]  [144.945357459904]     NaN   \n",
       "\n",
       "                        STOP_NAME     STOP_SUBURB   LATITUDE   LONGITUDE  \\\n",
       "6692   33-South Daly St/Dawson St  Brunswick West -37.769399  144.944169   \n",
       "22221                         NaN             NaN        NaN         NaN   \n",
       "\n",
       "      TICKETZONE ROUTES_USING_STOP                                  geometry  \n",
       "6692           1                58  (144.94417509159285, -37.76938584520886)  \n",
       "22221        NaN               NaN                                       NaN  "
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GS_DF_STOPS[(GS_DF_STOPS['STOP_NAME'] == '33-South Daly St/Dawson St') | (GS_DF_STOPS['stop_name'] == '33-South Daly St/Dawson St')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stop_id</th>\n",
       "      <th>stop_sequence</th>\n",
       "      <th>mode_id</th>\n",
       "      <th>direction_id</th>\n",
       "      <th>route_gtfs_id</th>\n",
       "      <th>route_short_name</th>\n",
       "      <th>route_long_name</th>\n",
       "      <th>stop_name</th>\n",
       "      <th>stop_suburb</th>\n",
       "      <th>stop_full_name</th>\n",
       "      <th>stop_lat</th>\n",
       "      <th>stop_lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>49276</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3-58</td>\n",
       "      <td>58</td>\n",
       "      <td>Toorak - West Coburg</td>\n",
       "      <td>[33-South Daly St/Dawson St]</td>\n",
       "      <td>Brunswick West</td>\n",
       "      <td>[33-South Daly St/Dawson St (Brunswick West)]</td>\n",
       "      <td>[-37.7695279063077]</td>\n",
       "      <td>[144.945357459904]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    stop_id  stop_sequence mode_id direction_id route_gtfs_id  \\\n",
       "112   49276             12       3            1          3-58   \n",
       "\n",
       "    route_short_name       route_long_name                     stop_name  \\\n",
       "112               58  Toorak - West Coburg  [33-South Daly St/Dawson St]   \n",
       "\n",
       "        stop_suburb                                 stop_full_name  \\\n",
       "112  Brunswick West  [33-South Daly St/Dawson St (Brunswick West)]   \n",
       "\n",
       "                stop_lat            stop_lon  \n",
       "112  [-37.7695279063077]  [144.945357459904]  "
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mid = pd.merge(GTFS_DF_ROUTESTOPS[GTFS_DF_ROUTESTOPS['route_gtfs_id'] == '3-58'], GTFS_DF_STOPS, left_on='stop_id', right_on='stop_id', how='left')\n",
    "mid[mid['stop_name'].apply(lambda x: any(['33-South Daly St/Dawson St' in i for i in x]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHP_GDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "GSA_DF_ROUTES = pd.read_csv('../local/gsa-routes.csv', dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DF_API2GS = GSA_DF_ROUTES.groupby('route_id')['route_gs_id'].unique().rename('route_gs_id').reset_index()\n",
    "df_api2gs_nunique = GSA_DF_ROUTES.groupby('route_id')['route_gs_id'].nunique().rename('route_gs_nunique').reset_index()\n",
    "DF_API2GS = pd.merge(DF_API2GS, df_api2gs_nunique, on='route_id')\n",
    "DF_API2GS['route_gs_len'] = DF_API2GS['route_gs_id'].apply(len)\n",
    "DF_API2GS['route_gs_nunique'] = DF_API2GS['route_gs_nunique'].apply(int)\n",
    "DF_API2GS['gs_na'] = DF_API2GS['route_gs_len'] != DF_API2GS['route_gs_nunique']\n",
    "DF_API2GS = pd.merge(DF_API2GS, API_DF_ROUTES, on='route_id')\n",
    "\n",
    "DF_API2GS[DF_API2GS['gs_na'] & (DF_API2GS['route_gs_nunique'] == 0)]['route_gtfs_id0'].unique() # array(['4', '1', '5'], dtype=object)\n",
    "DF_API2GS[DF_API2GS['route_gs_nunique'] >= 2]['route_gtfs_id0'].unique() # array(['1', '5'], dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_directions_endpoints = API_DF_ROUTES.apply(lambda x: f'/v3/directions/route/{x[\"route_id\"]}', axis=1).unique()\n",
    "\n",
    "api_all_directions = {}\n",
    "for i, endpoint in enumerate(api_directions_endpoints):\n",
    "    route_id = int(endpoint.split('/')[4])\n",
    "    directions = None\n",
    "    while directions is None:\n",
    "        try:\n",
    "            directions = get_data(endpoint)\n",
    "            # print(f'[{i}] Got directions for route {route_id}')\n",
    "        except requests.exceptions.HTTPError:\n",
    "            # print(f'Failed to get directions for route {route_id}. Retrying in 30 seconds...')\n",
    "            time.sleep(30)\n",
    "            continue\n",
    "    api_all_directions[route_id] = directions\n",
    "api_all_directions = { str(k): v['directions'] for k, v in api_all_directions.items() }\n",
    "# 2m - 3m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all([str(direction['route_id']) == str(k) for k, v in api_all_directions.items() for direction in v])\n",
    "\n",
    "API_DIRECTIONS_LIST = [direction for k, v in api_all_directions.items() for direction in v]\n",
    "\n",
    "API_DF_DIRECTIONS = pd.DataFrame(API_DIRECTIONS_LIST)[['route_id', 'route_type', 'direction_id', 'direction_name']]\n",
    "API_DF_DIRECTIONS.to_csv('../local/ptv-api/all_directions.csv', index=False)\n",
    "assert API_DF_DIRECTIONS[['route_id', 'route_type']].value_counts().max() <= 2\n",
    "\n",
    "API_DF_DIRECTIONS = pd.read_csv('../local/ptv-api/all_directions.csv')\n",
    "\n",
    "API_route_rtds = API_DF_DIRECTIONS[['route_id', 'route_type', 'direction_id']].values\n",
    "API_route_rtds = [(str(r), str(t), str(d)) for r, t, d in API_route_rtds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_STOPS_dict = {}\n",
    "for i, (route_id, route_type, direction_id) in enumerate(API_route_rtds):\n",
    "    # print(f'[{i}] Getting stops for route {route_id}, route type {route_type}, direction {direction_id}')\n",
    "    endpoint = f'/v3/stops/route/{route_id}/route_type/{route_type}?direction_id={direction_id}&include_geopath=true'\n",
    "    stops = None\n",
    "    while stops is None:\n",
    "        try:\n",
    "            stops = get_data(endpoint)\n",
    "            # print(f'[{i}] Got stops for route {route_id}')\n",
    "        except requests.exceptions.HTTPError:\n",
    "            # print(f'Failed to get stops for route {route_id}. Retrying in 30 seconds...')\n",
    "            time.sleep(30)\n",
    "            continue\n",
    "    API_STOPS_dict[route_id] = API_STOPS_dict.get(route_id, {})\n",
    "    API_STOPS_dict[route_id][direction_id] = stops\n",
    "# 3m - 5m\n",
    "    \n",
    "API_STOPS_dict = { str(k): { str(k2): v2 for k2, v2 in v.items()} for k, v in API_STOPS_dict.items() }\n",
    "with open('../local/ptv-api/all_stops_by_direction.json', 'w') as f:\n",
    "    f.write(json.dumps(API_STOPS_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_STOPS_STOPS = []\n",
    "API_STOPS_GEOPATHS = []\n",
    "for route_id, route_type, direction_id in API_route_rtds:\n",
    "    stops = API_STOPS_dict[route_id][direction_id]['stops']\n",
    "    for stop in stops:\n",
    "        if 'stop_ticket' not in stop:\n",
    "            # print(f'Route {route_id} has no ticket key for stop {stop[\"stop_id\"]}')\n",
    "            continue\n",
    "        if stop['stop_ticket'] is None:\n",
    "            # print(f'Route {route_id}: stop {stop[\"stop_id\"]}: stop ticket is None. Skipping...')\n",
    "            continue\n",
    "        for mid, v in stop['stop_ticket'].items():\n",
    "            mid = f'stop_{mid}'\n",
    "            assert mid not in stop, f'Key {mid} already exists in stop'\n",
    "            stop[mid] = v\n",
    "        if 'route_id' not in stop:\n",
    "            stop['route_id'] = route_id\n",
    "        if 'route_type' not in stop:\n",
    "            stop['route_type'] = route_type\n",
    "        if 'direction_id' not in stop:\n",
    "            stop['direction_id'] = direction_id\n",
    "        API_STOPS_STOPS.append(stop)\n",
    "    geopath = API_STOPS_dict[route_id][direction_id]['geopath']\n",
    "    for path in geopath:\n",
    "        if 'route_id' not in path:\n",
    "            path['route_id'] = route_id\n",
    "        if 'route_type' not in path:\n",
    "            path['route_type'] = route_type\n",
    "        if 'direction_id' not in path:\n",
    "            path['direction_id'] = direction_id\n",
    "        API_STOPS_GEOPATHS.append(path)\n",
    "        \n",
    "with open('../local/ptv-api/all_stops_stops.json', 'w') as f:\n",
    "    f.write(json.dumps(API_STOPS_STOPS))\n",
    "with open('../local/ptv-api/all_stops_geopaths.json', 'w') as f:\n",
    "    f.write(json.dumps(API_STOPS_GEOPATHS))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "API_STOPS_STOPS = json.load(open('../local/ptv-api/all_stops_stops.json'))\n",
    "API_STOPS_GEOPATHS = json.load(open('../local/ptv-api/all_stops_geopaths.json'))\n",
    "\n",
    "API_DF_STOPS = pd.DataFrame(API_STOPS_STOPS)\n",
    "API_DF_STOPS.drop(columns=['disruption_ids'], inplace=True)\n",
    "API_DF_STOPS['stop_ticket_zones'] = API_DF_STOPS['stop_ticket_zones'].apply(lambda x: ', '.join(map(str, x)) if isinstance(x, list) else x)\n",
    "API_DF_STOPS.drop(columns=['stop_ticket'], inplace=True)\n",
    "API_DF_STOPS['stop_is_regional'] = API_DF_STOPS['stop_zone'].apply(lambda x: 'Regional' in x)\n",
    "API_DF_STOPS['stop_zones'] = API_DF_STOPS['stop_ticket_zones']\n",
    "API_DF_STOPS.drop(columns=['stop_ticket_zones', 'stop_zone'], inplace=True)\n",
    "API_DF_STOPS = API_DF_STOPS[['stop_id', 'stop_name', 'stop_suburb', 'stop_latitude', 'stop_longitude', 'stop_sequence', 'route_id', 'direction_id',  'route_type',  'stop_landmark', 'stop_zones', 'stop_ticket_type', 'stop_is_free_fare_zone', 'stop_is_regional', 'stop_ticket_machine', 'stop_ticket_checks', 'stop_vline_reservation']]\n",
    "\n",
    "API_DF_STOPS.to_csv('../local/ptv-api/all_stops_stops.csv', index=False)\n",
    "API_DF_STOPS = pd.read_csv('../local/ptv-api/all_stops_stops.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_DF_STOPS_MIN = API_DF_STOPS[['stop_id', 'stop_name', 'stop_suburb', 'stop_latitude', 'stop_longitude']].drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stop_name         2\n",
       "stop_suburb       1\n",
       "stop_latitude     1\n",
       "stop_longitude    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "API_DF_STOPS_MIN.groupby('stop_id').aggregate({'stop_name': 'nunique', 'stop_suburb': 'nunique', 'stop_latitude': 'nunique', 'stop_longitude': 'nunique'}).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_DF_STOPS_MIN_GROUP = API_DF_STOPS_MIN.groupby('stop_id').aggregate({'stop_name': 'unique', 'stop_suburb': 'unique', 'stop_latitude': 'unique', 'stop_longitude': 'unique'})\n",
    "# 7s - 9s\n",
    "assert API_DF_STOPS_MIN_GROUP['stop_suburb'].apply(lambda x: len(x) == 1).all()\n",
    "assert API_DF_STOPS_MIN_GROUP['stop_latitude'].apply(lambda x: len(x) == 1).all()\n",
    "assert API_DF_STOPS_MIN_GROUP['stop_longitude'].apply(lambda x: len(x) == 1).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stop_name</th>\n",
       "      <th>stop_suburb</th>\n",
       "      <th>stop_latitude</th>\n",
       "      <th>stop_longitude</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stop_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>[Berwick Station, Berwick Railway Station]</td>\n",
       "      <td>[Berwick]</td>\n",
       "      <td>[-38.04041]</td>\n",
       "      <td>[145.345718]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>[Broadmeadows Station, Broadmeadows Railway St...</td>\n",
       "      <td>[Broadmeadows]</td>\n",
       "      <td>[-37.6830521]</td>\n",
       "      <td>[144.919617]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>[Caulfield Station, Caulfield Railway Station]</td>\n",
       "      <td>[Caulfield East]</td>\n",
       "      <td>[-37.8774567]</td>\n",
       "      <td>[145.042526]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>[Clayton Station, Clayton Railway Station]</td>\n",
       "      <td>[Clayton]</td>\n",
       "      <td>[-37.9246826]</td>\n",
       "      <td>[145.120529]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>[Craigieburn Station, Craigieburn Railway Stat...</td>\n",
       "      <td>[Craigieburn]</td>\n",
       "      <td>[-37.6019249]</td>\n",
       "      <td>[144.943314]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>[Dandenong Station, Dandenong Railway Station]</td>\n",
       "      <td>[Dandenong]</td>\n",
       "      <td>[-37.9899673]</td>\n",
       "      <td>[145.209732]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>[Essendon Station, Essendon Railway Station]</td>\n",
       "      <td>[Essendon]</td>\n",
       "      <td>[-37.75601]</td>\n",
       "      <td>[144.9162]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071</th>\n",
       "      <td>[Flinders Street Station, Flinders Street Rail...</td>\n",
       "      <td>[Melbourne City]</td>\n",
       "      <td>[-37.81831]</td>\n",
       "      <td>[144.966965]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>[Footscray Station, Footscray Railway Station]</td>\n",
       "      <td>[Footscray]</td>\n",
       "      <td>[-37.8010864]</td>\n",
       "      <td>[144.9032]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>[North Melbourne Station, North Melbourne Rail...</td>\n",
       "      <td>[West Melbourne]</td>\n",
       "      <td>[-37.807415]</td>\n",
       "      <td>[144.942566]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1153</th>\n",
       "      <td>[Pakenham Station, Pakenham Railway Station]</td>\n",
       "      <td>[Pakenham]</td>\n",
       "      <td>[-38.0802078]</td>\n",
       "      <td>[145.485977]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1162</th>\n",
       "      <td>[Richmond Station, Richmond Railway Station]</td>\n",
       "      <td>[Richmond]</td>\n",
       "      <td>[-37.8240738]</td>\n",
       "      <td>[144.990158]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1181</th>\n",
       "      <td>[Southern Cross Station, Southern Cross Railwa...</td>\n",
       "      <td>[Melbourne City]</td>\n",
       "      <td>[-37.8183327]</td>\n",
       "      <td>[144.95253]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187</th>\n",
       "      <td>[Sunbury Station, Sunbury Railway Station]</td>\n",
       "      <td>[Sunbury]</td>\n",
       "      <td>[-37.57909]</td>\n",
       "      <td>[144.727325]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1202</th>\n",
       "      <td>[Watergardens Station, Watergardens Railway St...</td>\n",
       "      <td>[Sydenham]</td>\n",
       "      <td>[-37.7011261]</td>\n",
       "      <td>[144.774185]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>[Sunshine Station, Sunshine Railway Station]</td>\n",
       "      <td>[Sunshine]</td>\n",
       "      <td>[-37.7885361]</td>\n",
       "      <td>[144.832886]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 stop_name       stop_suburb  \\\n",
       "stop_id                                                                        \n",
       "1021            [Berwick Station, Berwick Railway Station]         [Berwick]   \n",
       "1028     [Broadmeadows Station, Broadmeadows Railway St...    [Broadmeadows]   \n",
       "1036        [Caulfield Station, Caulfield Railway Station]  [Caulfield East]   \n",
       "1040            [Clayton Station, Clayton Railway Station]         [Clayton]   \n",
       "1044     [Craigieburn Station, Craigieburn Railway Stat...     [Craigieburn]   \n",
       "1049        [Dandenong Station, Dandenong Railway Station]       [Dandenong]   \n",
       "1064          [Essendon Station, Essendon Railway Station]        [Essendon]   \n",
       "1071     [Flinders Street Station, Flinders Street Rail...  [Melbourne City]   \n",
       "1072        [Footscray Station, Footscray Railway Station]       [Footscray]   \n",
       "1144     [North Melbourne Station, North Melbourne Rail...  [West Melbourne]   \n",
       "1153          [Pakenham Station, Pakenham Railway Station]        [Pakenham]   \n",
       "1162          [Richmond Station, Richmond Railway Station]        [Richmond]   \n",
       "1181     [Southern Cross Station, Southern Cross Railwa...  [Melbourne City]   \n",
       "1187            [Sunbury Station, Sunbury Railway Station]         [Sunbury]   \n",
       "1202     [Watergardens Station, Watergardens Railway St...        [Sydenham]   \n",
       "1218          [Sunshine Station, Sunshine Railway Station]        [Sunshine]   \n",
       "\n",
       "         stop_latitude stop_longitude  \n",
       "stop_id                                \n",
       "1021       [-38.04041]   [145.345718]  \n",
       "1028     [-37.6830521]   [144.919617]  \n",
       "1036     [-37.8774567]   [145.042526]  \n",
       "1040     [-37.9246826]   [145.120529]  \n",
       "1044     [-37.6019249]   [144.943314]  \n",
       "1049     [-37.9899673]   [145.209732]  \n",
       "1064       [-37.75601]     [144.9162]  \n",
       "1071       [-37.81831]   [144.966965]  \n",
       "1072     [-37.8010864]     [144.9032]  \n",
       "1144      [-37.807415]   [144.942566]  \n",
       "1153     [-38.0802078]   [145.485977]  \n",
       "1162     [-37.8240738]   [144.990158]  \n",
       "1181     [-37.8183327]    [144.95253]  \n",
       "1187       [-37.57909]   [144.727325]  \n",
       "1202     [-37.7011261]   [144.774185]  \n",
       "1218     [-37.7885361]   [144.832886]  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "API_DF_STOPS_MIN_GROUP[API_DF_STOPS_MIN_GROUP['stop_name'].apply(lambda x: len(x) > 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stop_id</th>\n",
       "      <th>stop_name</th>\n",
       "      <th>stop_suburb</th>\n",
       "      <th>stop_latitude</th>\n",
       "      <th>stop_longitude</th>\n",
       "      <th>stop_sequence</th>\n",
       "      <th>route_id</th>\n",
       "      <th>direction_id</th>\n",
       "      <th>route_type</th>\n",
       "      <th>stop_landmark</th>\n",
       "      <th>stop_zones</th>\n",
       "      <th>stop_ticket_type</th>\n",
       "      <th>stop_is_free_fare_zone</th>\n",
       "      <th>stop_is_regional</th>\n",
       "      <th>stop_ticket_machine</th>\n",
       "      <th>stop_ticket_checks</th>\n",
       "      <th>stop_vline_reservation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60197</th>\n",
       "      <td>1040</td>\n",
       "      <td>Clayton Railway Station</td>\n",
       "      <td>Clayton</td>\n",
       "      <td>-37.924683</td>\n",
       "      <td>145.120529</td>\n",
       "      <td>41</td>\n",
       "      <td>1721</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60235</th>\n",
       "      <td>1040</td>\n",
       "      <td>Clayton Railway Station</td>\n",
       "      <td>Clayton</td>\n",
       "      <td>-37.924683</td>\n",
       "      <td>145.120529</td>\n",
       "      <td>0</td>\n",
       "      <td>1721</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61822</th>\n",
       "      <td>1040</td>\n",
       "      <td>Clayton Railway Station</td>\n",
       "      <td>Clayton</td>\n",
       "      <td>-37.924683</td>\n",
       "      <td>145.120529</td>\n",
       "      <td>25</td>\n",
       "      <td>1823</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61852</th>\n",
       "      <td>1040</td>\n",
       "      <td>Clayton Railway Station</td>\n",
       "      <td>Clayton</td>\n",
       "      <td>-37.924683</td>\n",
       "      <td>145.120529</td>\n",
       "      <td>6</td>\n",
       "      <td>1823</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61883</th>\n",
       "      <td>1040</td>\n",
       "      <td>Clayton Railway Station</td>\n",
       "      <td>Clayton</td>\n",
       "      <td>-37.924683</td>\n",
       "      <td>145.120529</td>\n",
       "      <td>18</td>\n",
       "      <td>1824</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61911</th>\n",
       "      <td>1040</td>\n",
       "      <td>Clayton Railway Station</td>\n",
       "      <td>Clayton</td>\n",
       "      <td>-37.924683</td>\n",
       "      <td>145.120529</td>\n",
       "      <td>6</td>\n",
       "      <td>1824</td>\n",
       "      <td>39</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62430</th>\n",
       "      <td>1040</td>\n",
       "      <td>Clayton Railway Station</td>\n",
       "      <td>Clayton</td>\n",
       "      <td>-37.924683</td>\n",
       "      <td>145.120529</td>\n",
       "      <td>22</td>\n",
       "      <td>5838</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62455</th>\n",
       "      <td>1040</td>\n",
       "      <td>Clayton Railway Station</td>\n",
       "      <td>Clayton</td>\n",
       "      <td>-37.924683</td>\n",
       "      <td>145.120529</td>\n",
       "      <td>0</td>\n",
       "      <td>5838</td>\n",
       "      <td>43</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       stop_id                stop_name stop_suburb  stop_latitude  \\\n",
       "60197     1040  Clayton Railway Station     Clayton     -37.924683   \n",
       "60235     1040  Clayton Railway Station     Clayton     -37.924683   \n",
       "61822     1040  Clayton Railway Station     Clayton     -37.924683   \n",
       "61852     1040  Clayton Railway Station     Clayton     -37.924683   \n",
       "61883     1040  Clayton Railway Station     Clayton     -37.924683   \n",
       "61911     1040  Clayton Railway Station     Clayton     -37.924683   \n",
       "62430     1040  Clayton Railway Station     Clayton     -37.924683   \n",
       "62455     1040  Clayton Railway Station     Clayton     -37.924683   \n",
       "\n",
       "       stop_longitude  stop_sequence  route_id  direction_id  route_type  \\\n",
       "60197      145.120529             41      1721             0           3   \n",
       "60235      145.120529              0      1721            23           3   \n",
       "61822      145.120529             25      1823             0           3   \n",
       "61852      145.120529              6      1823            11           3   \n",
       "61883      145.120529             18      1824             0           3   \n",
       "61911      145.120529              6      1824            39           3   \n",
       "62430      145.120529             22      5838             0           3   \n",
       "62455      145.120529              0      5838            43           3   \n",
       "\n",
       "      stop_landmark stop_zones  stop_ticket_type  stop_is_free_fare_zone  \\\n",
       "60197           NaN          2               NaN                   False   \n",
       "60235           NaN          2               NaN                   False   \n",
       "61822           NaN          2               NaN                   False   \n",
       "61852           NaN          2               NaN                   False   \n",
       "61883           NaN          2               NaN                   False   \n",
       "61911           NaN          2               NaN                   False   \n",
       "62430           NaN          2               NaN                   False   \n",
       "62455           NaN          2               NaN                   False   \n",
       "\n",
       "       stop_is_regional  stop_ticket_machine  stop_ticket_checks  \\\n",
       "60197              True                False               False   \n",
       "60235              True                False               False   \n",
       "61822              True                False               False   \n",
       "61852              True                False               False   \n",
       "61883              True                False               False   \n",
       "61911              True                False               False   \n",
       "62430              True                False               False   \n",
       "62455              True                False               False   \n",
       "\n",
       "       stop_vline_reservation  \n",
       "60197                   False  \n",
       "60235                   False  \n",
       "61822                   False  \n",
       "61852                   False  \n",
       "61883                   False  \n",
       "61911                   False  \n",
       "62430                   False  \n",
       "62455                   False  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "API_DF_STOPS[API_DF_STOPS['stop_name'] == 'Clayton Railway Station']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
