{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hashlib import sha1\n",
    "import hmac\n",
    "import requests\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import pyptvgtfs\n",
    "SESSION = requests.Session()\n",
    "\n",
    "ENV = json.load(open('../local-env.json'))\n",
    "\n",
    "def get_ptv_api_url(\n",
    "        endpoint : str,\n",
    "        dev_id : str | int, \n",
    "        api_key : str | int,\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Returns the URL to use PTV TimeTable API.\n",
    "\n",
    "    Generates a signature from dev id (user id), API key, and endpoint.\n",
    "\n",
    "    See the following for more information:\n",
    "    - Home page: https://www.ptv.vic.gov.au/footer/data-and-reporting/datasets/ptv-timetable-api/\n",
    "    - Swagger UI: https://timetableapi.ptv.vic.gov.au/swagger/ui/index\n",
    "    - Swagger Docs JSON: https://timetableapi.ptv.vic.gov.au/swagger/docs/v3 (You can use this to find the endpoints you want to use.)\n",
    "    \"\"\"\n",
    "    assert endpoint.startswith('/'), f'Endpoint must start with /, got {endpoint}'\n",
    "    raw = f'{endpoint}{'&' if '?' in endpoint else '?'}devid={dev_id}'\n",
    "    hashed = hmac.new(api_key.encode('utf-8'), raw.encode('utf-8'), sha1)  # Encode the raw string to bytes\n",
    "    signature = hashed.hexdigest()\n",
    "    return f'https://timetableapi.ptv.vic.gov.au{raw}&signature={signature}'\n",
    "\n",
    "\n",
    "def get_data(endpoint : str, need_auth : bool = True):\n",
    "    \"\"\"\n",
    "    Returns the data from the URL.\n",
    "    \"\"\"\n",
    "    if need_auth:\n",
    "        url = get_ptv_api_url(endpoint, ENV['PTV_TIMETABLE_DEV_ID'], ENV['PTV_TIMETABLE_API_KEY'])\n",
    "    else:\n",
    "        url = f'https://timetableapi.ptv.vic.gov.au{endpoint}'\n",
    "    response = SESSION.get(url)\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_DOCS = get_data('/swagger/docs/v3', need_auth=False)\n",
    "STATIC_API_ENDPOINTS = [k for k in API_DOCS['paths'].keys() if '{' not in k]\n",
    "API_ROUTES : dict = get_data('/v3/routes')['routes']\n",
    "API_ROUTE_TYPES : dict = get_data('/v3/route_types')['route_types']\n",
    "API_DISRUPTIONS : dict = get_data('/v3/disruptions')['disruptions']\n",
    "API_DISRUPTION_MODES : dict = get_data('/v3/disruptions/modes')['disruption_modes']\n",
    "API_OUTLETS : dict = get_data('/v3/outlets')['outlets']\n",
    "API_DF_ROUTE_TYPES = pd.DataFrame(API_ROUTE_TYPES)\n",
    "API_DF_DISRUPTION_MODES = pd.DataFrame(API_DISRUPTION_MODES)\n",
    "API_DF_OUTLETS = pd.DataFrame(API_OUTLETS)\n",
    "# There are some faulty data in the outlets data. In particular, the latitude is > 0, which is not possible in Victoria.\n",
    "API_DF_OUTLETS['outlet_latitude'] = API_DF_OUTLETS['outlet_latitude'].apply(lambda x: -x if x > 0 else x)\n",
    "for route in API_ROUTES:\n",
    "    for k, v in route['route_service_status'].items():\n",
    "        assert k not in route, f'Key {k} already exists in route'\n",
    "        route[k] = v\n",
    "    del route['route_service_status']\n",
    "\n",
    "API_DF_ROUTES = pd.DataFrame(API_ROUTES) \n",
    "assert API_DF_ROUTES['route_id'].is_unique, 'route_id is not unique'\n",
    "assert API_DF_ROUTES['route_gtfs_id'].is_unique, 'route_gtfs_id is not unique'\n",
    "API_DF_ROUTES['route_id'] = API_DF_ROUTES['route_id'].apply(str)\n",
    "API_DF_ROUTES['route_type'] = API_DF_ROUTES['route_type'].apply(lambda x: str(int(x)) if not pd.isna(x) else x)\n",
    "\n",
    "API_DF_ROUTES = API_DF_ROUTES[['route_type', 'route_id', 'route_name', 'route_number']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHP_DIR = '../local/ptv-spatial-datasets'\n",
    "SHP_GDFS : gpd.GeoDataFrame = { f.split('.')[0]: gpd.read_file(os.path.join(SHP_DIR, f)) for f in os.listdir(SHP_DIR) if f.endswith('.shp') }\n",
    "for f in os.listdir(SHP_DIR):\n",
    "    if f.endswith('.txt'):\n",
    "        gdf_name = f.removesuffix('_column_names.txt').upper()\n",
    "        with open(os.path.join(SHP_DIR, f), 'r') as file:\n",
    "            gdf_column_names = [line.strip() for line in file.readlines()][4:]\n",
    "        assert gdf_name in SHP_GDFS, f'{gdf_name} not in GDFS'\n",
    "        for line in gdf_column_names:\n",
    "            assert ' = ' in line, f'Invalid line: {line}'\n",
    "        gdf_column_names = { line.split(' = ')[0]: line.split(' = ')[1] for line in gdf_column_names }\n",
    "        SHP_GDFS[gdf_name].rename(columns=gdf_column_names, inplace=True)\n",
    "# SHP_DF_ROUTES : pd.DataFrame = pd.concat([gdf for k, gdf in SHP_GDFS.items() if 'ROUTE' in k])\n",
    "# SHP_DF_ROUTES['route_idx'] = SHP_DF_ROUTES['ROUTE_ID'].apply(lambda x: x.split('-'))\n",
    "# SHP_DF_ROUTES['route_id0'] = SHP_DF_ROUTES['route_idx'].apply(lambda x: x[0])\n",
    "# SHP_DF_ROUTES['route_id1'] = SHP_DF_ROUTES['route_idx'].apply(lambda x: x[1])\n",
    "# SHP_DF_ROUTES['route_id2'] = SHP_DF_ROUTES['route_idx'].apply(lambda x: x[2] if len(x) > 4 else np.nan)\n",
    "# SHP_DF_ROUTES['route_id3'] = SHP_DF_ROUTES['route_idx'].apply(lambda x: x[-2])\n",
    "# SHP_DF_ROUTES['route_id4'] = SHP_DF_ROUTES['route_idx'].apply(lambda x: x[-1])\n",
    "# SHP_DF_ROUTES['route_id01'] = SHP_DF_ROUTES['route_id0'] + '-' + SHP_DF_ROUTES['route_id1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\An\\AppData\\Local\\Temp\\ipykernel_25076\\2698581839.py:3: UserWarning: Geometry column does not contain geometry.\n",
      "  SHP_DF_STOPS['geometry'] = SHP_DF_STOPS['geometry'].apply(lambda x: x.coords[0])\n"
     ]
    }
   ],
   "source": [
    "SHP_DF_STOPS : pd.DataFrame = pd.concat([gdf for k, gdf in SHP_GDFS.items() if 'PTV_METRO_TRAIN_STATION' == k or 'STOP' in k])\n",
    "# SHP_GDFS[]\n",
    "SHP_DF_STOPS['geometry'] = SHP_DF_STOPS['geometry'].apply(lambda x: x.coords[0])\n",
    "SHP_DF_STOPS['STOP_FULL_NAME'] = SHP_DF_STOPS['STOP_NAME']\n",
    "SHP_DF_STOPS['STOP_SUBURB'] = SHP_DF_STOPS['STOP_FULL_NAME'].apply(lambda x: x.split('(', 1)[1].lstrip('(').rstrip(')') if '(' in x else np.nan)\n",
    "SHP_DF_STOPS['STOP_NAME'] = SHP_DF_STOPS['STOP_FULL_NAME'].apply(lambda x: x.split('(', 1)[0].strip())\n",
    "\n",
    "# Inspection of the data shows that there are some stops with no suburb. We will manually fill these in.\n",
    "SHP_DF_STOPS[SHP_DF_STOPS['STOP_SUBURB'].isna()]\n",
    "\n",
    "def custom_stop_suburb(x):\n",
    "    if x['STOP_ID'] == '35117':\n",
    "        assert x['STOP_NAME'] == 'Ascot St/Sturt St', x['STOP_NAME']\n",
    "        return 'Ballarat Central'\n",
    "    return x['STOP_SUBURB']\n",
    "\n",
    "SHP_DF_STOPS['STOP_SUBURB'] = SHP_DF_STOPS.apply(custom_stop_suburb, axis=1)\n",
    "\n",
    "SHP_DF_STOPS = SHP_DF_STOPS.groupby('STOP_ID').aggregate({'STOP_NAME': 'unique', 'STOP_SUBURB': 'unique', 'STOP_FULL_NAME': 'unique', 'LATITUDE': 'unique', 'LONGITUDE': 'unique', 'TICKETZONE': 'unique', 'ROUTES_USING_STOP': 'unique', 'geometry': 'unique'})\n",
    "# 7s - 10s\n",
    "SHP_DF_STOPS.reset_index(inplace=True)\n",
    "\n",
    "for col in SHP_DF_STOPS.columns:\n",
    "    if col != 'STOP_ID':\n",
    "        SHP_DF_STOPS[f'{col}_len'] = SHP_DF_STOPS[col].apply(len)\n",
    "\n",
    "for col in ['STOP_NAME', 'STOP_SUBURB', 'STOP_FULL_NAME', 'LATITUDE', 'LONGITUDE', 'geometry']:\n",
    "    assert SHP_DF_STOPS[f'{col}_len'].max() == 1\n",
    "    SHP_DF_STOPS[col] = SHP_DF_STOPS[col].apply(lambda x: x[0])\n",
    "\n",
    "SHP_DF_STOPS['TICKETZONE'] = SHP_DF_STOPS['TICKETZONE'].apply(lambda x: ','.join([str(i) for i in x if not pd.isna(i)]))\n",
    "SHP_DF_STOPS['ROUTES_USING_STOP'] = SHP_DF_STOPS['ROUTES_USING_STOP'].apply(lambda x: ','.join([str(i) for i in x if not pd.isna(i)]))\n",
    "\n",
    "SHP_DF_STOPS.drop(columns=[col for col in SHP_DF_STOPS.columns if col.endswith('_len')], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "GTFS = pyptvgtfs.process_gtfs_zip('../downloads/20240312_113156/gtfs.zip', '')\n",
    "GTFS.drop(columns=['version_id'], inplace=True)\n",
    "GTFS_DFS = GTFS.set_index(['mode_id', 'table_name'])['df'].to_dict()\n",
    "new_GTFS_DFS = {}\n",
    "for k, v in GTFS_DFS.items():\n",
    "    new_GTFS_DFS[k[0]] = new_GTFS_DFS.get(k[0], {})\n",
    "    new_GTFS_DFS[k[0]][k[1]] = v\n",
    "GTFS_DFS : dict[str, dict[str, pd.DataFrame]] = new_GTFS_DFS\n",
    "for mid in GTFS_DFS:\n",
    "    for tn in GTFS_DFS[mid]:\n",
    "        GTFS_DFS[mid][tn]['mode_id'] = mid\n",
    "# 45s - 1m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "GTFS_DF_ROUTES = pd.concat([GTFS_DFS[mid]['routes'] for mid in GTFS_DFS])\n",
    "# 1m - 2m\n",
    "GTFS_DF_ROUTES['route_idx'] = GTFS_DF_ROUTES['route_id'].apply(lambda x: x.split('-'))\n",
    "GTFS_DF_ROUTES['route_id0'] = GTFS_DF_ROUTES['route_idx'].apply(lambda x: x[0])\n",
    "GTFS_DF_ROUTES['route_id1'] = GTFS_DF_ROUTES['route_idx'].apply(lambda x: x[1])\n",
    "GTFS_DF_ROUTES['route_id2'] = GTFS_DF_ROUTES['route_idx'].apply(lambda x: x[2] if len(x) > 4 else np.nan)\n",
    "GTFS_DF_ROUTES['route_id3'] = GTFS_DF_ROUTES['route_idx'].apply(lambda x: x[-2])\n",
    "GTFS_DF_ROUTES['route_id4'] = GTFS_DF_ROUTES['route_idx'].apply(lambda x: x[-1])\n",
    "GTFS_DF_ROUTES['route_id01'] = GTFS_DF_ROUTES['mode_id'] + '-' + GTFS_DF_ROUTES['route_id1']\n",
    "GTFS_DF_ROUTES['route_gtfs_id'] = GTFS_DF_ROUTES.apply(lambda x: f'{x[\"mode_id\"]}-{x[\"route_id1\"]}' + (x['route_id2'] if x['mode_id'] == '4' and pd.notna(x['route_id2']) else ''), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GTFS_DF_STOPS = pd.concat([GTFS_DFS[mid]['stops'] for mid in GTFS_DFS])\n",
    "GTFS_DF_STOP_TIMES = pd.concat([GTFS_DFS[mid]['stop_times'] for mid in GTFS_DFS])\n",
    "GTFS_DF_TRIPS = pd.concat([GTFS_DFS[mid]['trips'] for mid in GTFS_DFS])\n",
    "GTFS_DF_TRIPS = GTFS_DF_TRIPS.merge(GTFS_DF_ROUTES, on='route_id', how='left', suffixes=('', '_route'))\n",
    "GTFS_DF_TRIPS.drop(columns=['mode_id_route'], inplace=True)\n",
    "\n",
    "# GTFS_DF_STOP_TIMES = GTFS_DF_STOP_TIMES.merge(GTFS_DF_STOPS, on='stop_id', suffixes=('', '_stop'))\n",
    "GTFS_DF_STOP_TIMES = GTFS_DF_STOP_TIMES.merge(GTFS_DF_TRIPS, on='trip_id', suffixes=('', '_trip'))\n",
    "# 1m 30s\n",
    "\n",
    "GTFS_DF_STOP_TIMES = GTFS_DF_STOP_TIMES[['stop_id', 'stop_sequence', 'mode_id', 'direction_id', 'route_gtfs_id', 'route_short_name', 'route_long_name']].drop_duplicates()\n",
    "# 20s\n",
    "GTFS_DF_ROUTESTOPS = GTFS_DF_STOP_TIMES.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "GTFS_DF_STOPS['stop_full_name'] = GTFS_DF_STOPS['stop_name']\n",
    "GTFS_DF_STOPS['stop_suburb'] = GTFS_DF_STOPS['stop_full_name'].apply(lambda x: x.split('(', 1))\n",
    "GTFS_DF_STOPS['stop_suburb'] = GTFS_DF_STOPS['stop_suburb'].apply(lambda x: x[1].removesuffix(')') if len(x) == 2 else np.nan)\n",
    "GTFS_DF_STOPS['stop_name'] = GTFS_DF_STOPS['stop_full_name'].apply(lambda x: x.split('(')[0].strip())\n",
    "\n",
    "# Assert no stop_name contains both ',' and '('\n",
    "assert not (GTFS_DF_STOPS['stop_suburb'].notna() & GTFS_DF_STOPS['stop_full_name'].apply(lambda x: ',' in x)).any()\n",
    "\n",
    "GTFS_DF_STOPS['stop_suburb'] = GTFS_DF_STOPS.apply(lambda x: x['stop_name'].split(', ')[1] if ',' in x['stop_name'] else x['stop_suburb'], axis=1)\n",
    "\n",
    "GTFS_DF_STOPS['stop_name'] = GTFS_DF_STOPS.apply(lambda x: x['stop_name'].split(', ')[0] if ',' in x['stop_name'] else x['stop_name'], axis=1)\n",
    "\n",
    "# Inspect NaN stop_suburb\n",
    "GTFS_DF_STOPS[GTFS_DF_STOPS['stop_suburb'].isna()]\n",
    "\n",
    "# Custom stop_name and stop_suburb\n",
    "\n",
    "def custom_stop_name(x):\n",
    "    if x['stop_id'] == '5588':\n",
    "        assert x['stop_name'] == 'Rosemary St'\n",
    "        return 'Rosemary St/High St'\n",
    "    return x['stop_name']\n",
    "\n",
    "def custom_stop_suburb(x):\n",
    "    if x['stop_id'] == '5588':\n",
    "        assert x['stop_name'] == 'Rosemary St' or x['stop_name'] == 'Rosemary St/High St', x['stop_name']\n",
    "        return 'Templestowe Lower'\n",
    "    if x['stop_id'] == '28185':\n",
    "        assert x['stop_name'] == 'Keysborough South Shopping Centre/Braeside-Dandenong Rd', x['stop_name']\n",
    "        return 'Keysborough'\n",
    "    if x['stop_id'] == '35117':\n",
    "        assert x['stop_name'] == 'Ascot St/Sturt St', x['stop_name']\n",
    "        return 'Ballarat Central'\n",
    "    return x['stop_suburb']\n",
    "\n",
    "\n",
    "GTFS_DF_STOPS['stop_name'] = GTFS_DF_STOPS.apply(lambda x: custom_stop_name(x), axis=1)\n",
    "GTFS_DF_STOPS['stop_suburb'] = GTFS_DF_STOPS.apply(lambda x: custom_stop_suburb(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "GTFS_DF_STOPS = GTFS_DF_STOPS.groupby('stop_id').aggregate({'stop_name': 'unique', 'stop_suburb': 'unique', 'stop_full_name': 'unique', 'stop_lat': 'unique', 'stop_lon': 'unique'})\n",
    "# 5s - 7s\n",
    "\n",
    "GTFS_DF_STOPS.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in GTFS_DF_STOPS.columns:\n",
    "    if col != 'stop_id':\n",
    "        GTFS_DF_STOPS[f'{col}_len'] = GTFS_DF_STOPS[col].apply(len)\n",
    "\n",
    "# Inspect len columns to find stops with multiple names, suburbs, etc.\n",
    "# GTFS_DF_STOPS[['stop_name_len', 'stop_suburb_len', 'stop_full_name_len', 'stop_lat_len', 'stop_lon_len']].max()\n",
    "        \n",
    "assert GTFS_DF_STOPS['stop_suburb_len'].max() == 1\n",
    "\n",
    "assert GTFS_DF_STOPS.apply(lambda x: x['stop_name_len'] == 1 or (x['stop_lat_len'] == 1 and x['stop_lon_len'] == 1), axis=1).all()\n",
    "\n",
    "GTFS_DF_STOPS['stop_suburb'] = GTFS_DF_STOPS['stop_suburb'].apply(lambda x: x[0])\n",
    "\n",
    "GTFS_DF_STOPS.drop(columns=[col for col in GTFS_DF_STOPS.columns if col.endswith('_len')], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "GS_DF_STOPS = pd.merge(GTFS_DF_STOPS, SHP_DF_STOPS, left_on='stop_id', right_on='STOP_ID', suffixes=('_gtfs', '_shp'), how='outer')\n",
    "\n",
    "GS_DF_STOPS.drop(columns=['stop_full_name', 'STOP_FULL_NAME'], inplace=True)\n",
    "\n",
    "assert GS_DF_STOPS[GS_DF_STOPS['stop_name'].apply(lambda x: isinstance(x, np.ndarray) and len(x) > 1)]['STOP_ID'].notna().all()\n",
    "\n",
    "# GS_DF_STOPS[GS_DF_STOPS['stop_id'].isna()]\n",
    "# assert GS_DF_STOPS[GS_DF_STOPS['stop_name'].apply(lambda x: isinstance(x, np.ndarray) and len(x) > 1)]['STOP_ID'].notna().all()\n",
    "assert GS_DF_STOPS[GS_DF_STOPS['STOP_ID'].notna() & GS_DF_STOPS['stop_id'].notna()].apply(lambda x: x['STOP_NAME'] in x['stop_name'] if len(x['stop_name']) > 1 else True, axis=1).all()\n",
    "\n",
    "assert GS_DF_STOPS[GS_DF_STOPS['stop_lat'].apply(lambda x: isinstance(x, np.ndarray) and len(x) > 1)]['LATITUDE'].notna().all()\n",
    "\n",
    "assert GS_DF_STOPS[GS_DF_STOPS['stop_lon'].apply(lambda x: isinstance(x, np.ndarray) and len(x) > 1)]['LONGITUDE'].notna().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stop_id</th>\n",
       "      <th>stop_name</th>\n",
       "      <th>stop_suburb</th>\n",
       "      <th>stop_full_name</th>\n",
       "      <th>stop_lat</th>\n",
       "      <th>stop_lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>1109</td>\n",
       "      <td>[Inkerman St/Barkly St]</td>\n",
       "      <td>St Kilda</td>\n",
       "      <td>[Inkerman St/Barkly St (St Kilda)]</td>\n",
       "      <td>[-37.8637295981912, -37.8637292085664]</td>\n",
       "      <td>[144.981937426538, 144.981914702951]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    stop_id                stop_name stop_suburb  \\\n",
       "979    1109  [Inkerman St/Barkly St]    St Kilda   \n",
       "\n",
       "                         stop_full_name  \\\n",
       "979  [Inkerman St/Barkly St (St Kilda)]   \n",
       "\n",
       "                                   stop_lat  \\\n",
       "979  [-37.8637295981912, -37.8637292085664]   \n",
       "\n",
       "                                 stop_lon  \n",
       "979  [144.981937426538, 144.981914702951]  "
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GTFS_DF_STOPS[GTFS_DF_STOPS['stop_id'] == '1109']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stop_id</th>\n",
       "      <th>stop_name</th>\n",
       "      <th>stop_suburb</th>\n",
       "      <th>stop_lat</th>\n",
       "      <th>stop_lon</th>\n",
       "      <th>STOP_ID</th>\n",
       "      <th>STOP_NAME</th>\n",
       "      <th>STOP_SUBURB</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>TICKETZONE</th>\n",
       "      <th>ROUTES_USING_STOP</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [stop_id, stop_name, stop_suburb, stop_lat, stop_lon, STOP_ID, STOP_NAME, STOP_SUBURB, LATITUDE, LONGITUDE, TICKETZONE, ROUTES_USING_STOP, geometry]\n",
       "Index: []"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = GS_DF_STOPS[GS_DF_STOPS['LATITUDE'].notna() & GS_DF_STOPS['stop_lat'].notna()]\n",
    "k[k.apply(lambda x: x['LATITUDE'] in x['stop_lat'] if len(x['stop_lat']) > 1 else False, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[241], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m GS_DF_STOPS[GS_DF_STOPS[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLONGITUDE\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnotna() \u001b[38;5;241m&\u001b[39m GS_DF_STOPS[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstop_lon\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnotna()]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLONGITUDE\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstop_lon\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstop_lon\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mall()\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert GS_DF_STOPS[GS_DF_STOPS['LONGITUDE'].notna() & GS_DF_STOPS['stop_lon'].notna()].apply(lambda x: x['LONGITUDE'] in x['stop_lon'] if len(x['stop_lon']) > 1 else True, axis=1).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "GS_DF_STOPS['stop_name'] = GS_DF_STOPS.apply(lambda x: (x['STOP_NAME'] if (x['STOP_NAME'] in x['stop_name']) else x['stop_name'][0]) if isinstance(x['stop_name'], np.ndarray) else x['stop_name'], axis=1)\n",
    "\n",
    "\n",
    "GS_DF_STOPS['stop_lat'] = GS_DF_STOPS.apply(lambda x: (x['LATITUDE'] if (x['LATITUDE'] in x['stop_lat']) else x['stop_lat'][0]) if isinstance(x['stop_lat'], np.ndarray) else x['stop_lat'], axis=1)\n",
    "GS_DF_STOPS['stop_lon'] = GS_DF_STOPS.apply(lambda x: (x['LONGITUDE'] if (x['LONGITUDE'] in x['stop_lon']) else x['stop_lon'][0]) if isinstance(x['stop_lon'], np.ndarray) else x['stop_lon'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stop_id</th>\n",
       "      <th>stop_name</th>\n",
       "      <th>stop_suburb</th>\n",
       "      <th>stop_lat</th>\n",
       "      <th>stop_lon</th>\n",
       "      <th>STOP_ID</th>\n",
       "      <th>STOP_NAME</th>\n",
       "      <th>STOP_SUBURB</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>TICKETZONE</th>\n",
       "      <th>ROUTES_USING_STOP</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>Dole Ave/Cheddar Rd</td>\n",
       "      <td>Reservoir</td>\n",
       "      <td>-37.700775</td>\n",
       "      <td>145.018951</td>\n",
       "      <td>1000</td>\n",
       "      <td>Dole Ave/Cheddar Rd</td>\n",
       "      <td>Reservoir</td>\n",
       "      <td>-37.700775</td>\n",
       "      <td>145.018951</td>\n",
       "      <td>2</td>\n",
       "      <td>556</td>\n",
       "      <td>(145.01895679496207, -37.700761839394126)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>Rex St/Taylors Rd</td>\n",
       "      <td>Kings Park</td>\n",
       "      <td>-37.726975</td>\n",
       "      <td>144.776152</td>\n",
       "      <td>10001</td>\n",
       "      <td>Rex St/Taylors Rd</td>\n",
       "      <td>Kings Park</td>\n",
       "      <td>-37.726975</td>\n",
       "      <td>144.776152</td>\n",
       "      <td>2</td>\n",
       "      <td>418</td>\n",
       "      <td>(144.77615808013866, -37.726961811610934)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002</td>\n",
       "      <td>Yuille St/Centenary Ave</td>\n",
       "      <td>Melton</td>\n",
       "      <td>-37.676160</td>\n",
       "      <td>144.595789</td>\n",
       "      <td>10002</td>\n",
       "      <td>Yuille St/Centenary Ave</td>\n",
       "      <td>Melton</td>\n",
       "      <td>-37.676160</td>\n",
       "      <td>144.595789</td>\n",
       "      <td>2</td>\n",
       "      <td>458</td>\n",
       "      <td>(144.59579487015532, -37.676146816695955)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10009</td>\n",
       "      <td>Gum Rd/Main Rd West</td>\n",
       "      <td>Albanvale</td>\n",
       "      <td>-37.741497</td>\n",
       "      <td>144.775899</td>\n",
       "      <td>10009</td>\n",
       "      <td>Gum Rd/Main Rd West</td>\n",
       "      <td>Albanvale</td>\n",
       "      <td>-37.741497</td>\n",
       "      <td>144.775899</td>\n",
       "      <td>2</td>\n",
       "      <td>424</td>\n",
       "      <td>(144.77590499996512, -37.741483851234776)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001</td>\n",
       "      <td>Lloyd Ave/Cheddar Rd</td>\n",
       "      <td>Reservoir</td>\n",
       "      <td>-37.699183</td>\n",
       "      <td>145.019685</td>\n",
       "      <td>1001</td>\n",
       "      <td>Lloyd Ave/Cheddar Rd</td>\n",
       "      <td>Reservoir</td>\n",
       "      <td>-37.699183</td>\n",
       "      <td>145.019685</td>\n",
       "      <td>2</td>\n",
       "      <td>556</td>\n",
       "      <td>(145.01969083617018, -37.69916982951895)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28374</th>\n",
       "      <td>9991</td>\n",
       "      <td>Donald St/Wood St</td>\n",
       "      <td>Preston</td>\n",
       "      <td>-37.735366</td>\n",
       "      <td>145.022375</td>\n",
       "      <td>9991</td>\n",
       "      <td>Donald St/Wood St</td>\n",
       "      <td>Preston</td>\n",
       "      <td>-37.735366</td>\n",
       "      <td>145.022375</td>\n",
       "      <td>1,2</td>\n",
       "      <td>555</td>\n",
       "      <td>(145.0223811139475, -37.73535279930797)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28375</th>\n",
       "      <td>9992</td>\n",
       "      <td>Highview Rd/Wood St</td>\n",
       "      <td>Preston</td>\n",
       "      <td>-37.735117</td>\n",
       "      <td>145.019886</td>\n",
       "      <td>9992</td>\n",
       "      <td>Highview Rd/Wood St</td>\n",
       "      <td>Preston</td>\n",
       "      <td>-37.735117</td>\n",
       "      <td>145.019886</td>\n",
       "      <td>1,2</td>\n",
       "      <td>555</td>\n",
       "      <td>(145.01989207591876, -37.73510385903128)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28376</th>\n",
       "      <td>9993</td>\n",
       "      <td>Plenty Rd/Wood St</td>\n",
       "      <td>Preston</td>\n",
       "      <td>-37.734193</td>\n",
       "      <td>145.013681</td>\n",
       "      <td>9993</td>\n",
       "      <td>Plenty Rd/Wood St</td>\n",
       "      <td>Preston</td>\n",
       "      <td>-37.734460</td>\n",
       "      <td>145.014014</td>\n",
       "      <td>1,2</td>\n",
       "      <td>555</td>\n",
       "      <td>(145.0140201207862, -37.73444685842192)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28377</th>\n",
       "      <td>9994</td>\n",
       "      <td>Yellow Gum Rd/Copperfield Dr</td>\n",
       "      <td>Delahey</td>\n",
       "      <td>-37.713855</td>\n",
       "      <td>144.771894</td>\n",
       "      <td>9994</td>\n",
       "      <td>Yellow Gum Rd/Copperfield Dr</td>\n",
       "      <td>Delahey</td>\n",
       "      <td>-37.713855</td>\n",
       "      <td>144.771894</td>\n",
       "      <td>2</td>\n",
       "      <td>425</td>\n",
       "      <td>(144.77189999987596, -37.7138417920479)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28378</th>\n",
       "      <td>9995</td>\n",
       "      <td>Carberry Dr/Gisborne-Melton Rd</td>\n",
       "      <td>Kurunjang</td>\n",
       "      <td>-37.672455</td>\n",
       "      <td>144.598392</td>\n",
       "      <td>9995</td>\n",
       "      <td>Carberry Dr/Gisborne-Melton Rd</td>\n",
       "      <td>Kurunjang</td>\n",
       "      <td>-37.672455</td>\n",
       "      <td>144.598392</td>\n",
       "      <td>2</td>\n",
       "      <td>458</td>\n",
       "      <td>(144.5983980368925, -37.67244178714646)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28379 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      stop_id                       stop_name stop_suburb   stop_lat  \\\n",
       "0        1000             Dole Ave/Cheddar Rd   Reservoir -37.700775   \n",
       "1       10001               Rex St/Taylors Rd  Kings Park -37.726975   \n",
       "2       10002         Yuille St/Centenary Ave      Melton -37.676160   \n",
       "3       10009             Gum Rd/Main Rd West   Albanvale -37.741497   \n",
       "4        1001            Lloyd Ave/Cheddar Rd   Reservoir -37.699183   \n",
       "...       ...                             ...         ...        ...   \n",
       "28374    9991               Donald St/Wood St     Preston -37.735366   \n",
       "28375    9992             Highview Rd/Wood St     Preston -37.735117   \n",
       "28376    9993               Plenty Rd/Wood St     Preston -37.734193   \n",
       "28377    9994    Yellow Gum Rd/Copperfield Dr     Delahey -37.713855   \n",
       "28378    9995  Carberry Dr/Gisborne-Melton Rd   Kurunjang -37.672455   \n",
       "\n",
       "         stop_lon STOP_ID                       STOP_NAME STOP_SUBURB  \\\n",
       "0      145.018951    1000             Dole Ave/Cheddar Rd   Reservoir   \n",
       "1      144.776152   10001               Rex St/Taylors Rd  Kings Park   \n",
       "2      144.595789   10002         Yuille St/Centenary Ave      Melton   \n",
       "3      144.775899   10009             Gum Rd/Main Rd West   Albanvale   \n",
       "4      145.019685    1001            Lloyd Ave/Cheddar Rd   Reservoir   \n",
       "...           ...     ...                             ...         ...   \n",
       "28374  145.022375    9991               Donald St/Wood St     Preston   \n",
       "28375  145.019886    9992             Highview Rd/Wood St     Preston   \n",
       "28376  145.013681    9993               Plenty Rd/Wood St     Preston   \n",
       "28377  144.771894    9994    Yellow Gum Rd/Copperfield Dr     Delahey   \n",
       "28378  144.598392    9995  Carberry Dr/Gisborne-Melton Rd   Kurunjang   \n",
       "\n",
       "        LATITUDE   LONGITUDE TICKETZONE ROUTES_USING_STOP  \\\n",
       "0     -37.700775  145.018951          2               556   \n",
       "1     -37.726975  144.776152          2               418   \n",
       "2     -37.676160  144.595789          2               458   \n",
       "3     -37.741497  144.775899          2               424   \n",
       "4     -37.699183  145.019685          2               556   \n",
       "...          ...         ...        ...               ...   \n",
       "28374 -37.735366  145.022375        1,2               555   \n",
       "28375 -37.735117  145.019886        1,2               555   \n",
       "28376 -37.734460  145.014014        1,2               555   \n",
       "28377 -37.713855  144.771894          2               425   \n",
       "28378 -37.672455  144.598392          2               458   \n",
       "\n",
       "                                        geometry  \n",
       "0      (145.01895679496207, -37.700761839394126)  \n",
       "1      (144.77615808013866, -37.726961811610934)  \n",
       "2      (144.59579487015532, -37.676146816695955)  \n",
       "3      (144.77590499996512, -37.741483851234776)  \n",
       "4       (145.01969083617018, -37.69916982951895)  \n",
       "...                                          ...  \n",
       "28374    (145.0223811139475, -37.73535279930797)  \n",
       "28375   (145.01989207591876, -37.73510385903128)  \n",
       "28376    (145.0140201207862, -37.73444685842192)  \n",
       "28377    (144.77189999987596, -37.7138417920479)  \n",
       "28378    (144.5983980368925, -37.67244178714646)  \n",
       "\n",
       "[28379 rows x 13 columns]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GS_DF_STOPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for col in ['stop_name', 'stop_suburb', 'stop_full_name', 'stop_lat', 'stop_lon']:\n",
    "    assert GTFS_DF_STOPS[f'{col}_len'].max() == 1\n",
    "    GTFS_DF_STOPS[col] = GTFS_DF_STOPS[col].apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect NaN stop_suburb\n",
    "GTFS_DF_STOPS[GTFS_DF_STOPS['stop_suburb'].isna()]\n",
    "\n",
    "# Custom stop_name and stop_suburb\n",
    "\n",
    "def custom_stop_name(x):\n",
    "    if x['stop_id'] == '5588':\n",
    "        assert x['stop_name'] == 'Rosemary St'\n",
    "        return 'Rosemary St/High St'\n",
    "    return x['stop_name']\n",
    "\n",
    "def custom_stop_suburb(x):\n",
    "    if x['stop_id'] == '5588':\n",
    "        assert x['stop_name'] == 'Rosemary St' or x['stop_name'] == 'Rosemary St/High St', x['stop_name']\n",
    "        return 'Templestowe Lower'\n",
    "    if x['stop_id'] == '28185':\n",
    "        assert x['stop_name'] == 'Keysborough South Shopping Centre/Braeside-Dandenong Rd', x['stop_name']\n",
    "        return 'Keysborough'\n",
    "    if x['stop_id'] == '35117':\n",
    "        assert x['stop_name'] == 'Ascot St/Sturt St', x['stop_name']\n",
    "        return 'Ballarat Central'\n",
    "    return x['stop_suburb']\n",
    "\n",
    "\n",
    "GTFS_DF_STOPS['stop_name'] = GTFS_DF_STOPS.apply(lambda x: custom_stop_name(x), axis=1)\n",
    "GTFS_DF_STOPS['stop_suburb'] = GTFS_DF_STOPS.apply(lambda x: custom_stop_suburb(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Keysborough South Shopping Centre/Braeside-Dandenong Rd',\n",
       "       'Rosemary St', 'Ascot St/Sturt St'], dtype=object)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GTFS_DF_STOPS[GTFS_DF_STOPS['stop_suburb'].isna()]['stop_name'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GTFS_DF_STOPS[GTFS_DF_STOPS['stop_suburb'].isna()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "GSA_DF_ROUTES = pd.read_csv('../local/gsa-routes.csv', dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DF_API2GS = GSA_DF_ROUTES.groupby('route_id')['route_gs_id'].unique().rename('route_gs_id').reset_index()\n",
    "df_api2gs_nunique = GSA_DF_ROUTES.groupby('route_id')['route_gs_id'].nunique().rename('route_gs_nunique').reset_index()\n",
    "DF_API2GS = pd.merge(DF_API2GS, df_api2gs_nunique, on='route_id')\n",
    "DF_API2GS['route_gs_len'] = DF_API2GS['route_gs_id'].apply(len)\n",
    "DF_API2GS['route_gs_nunique'] = DF_API2GS['route_gs_nunique'].apply(int)\n",
    "DF_API2GS['gs_na'] = DF_API2GS['route_gs_len'] != DF_API2GS['route_gs_nunique']\n",
    "DF_API2GS = pd.merge(DF_API2GS, API_DF_ROUTES, on='route_id')\n",
    "\n",
    "DF_API2GS[DF_API2GS['gs_na'] & (DF_API2GS['route_gs_nunique'] == 0)]['route_gtfs_id0'].unique() # array(['4', '1', '5'], dtype=object)\n",
    "DF_API2GS[DF_API2GS['route_gs_nunique'] >= 2]['route_gtfs_id0'].unique() # array(['1', '5'], dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_directions_endpoints = API_DF_ROUTES.apply(lambda x: f'/v3/directions/route/{x[\"route_id\"]}', axis=1).unique()\n",
    "\n",
    "api_all_directions = {}\n",
    "for i, endpoint in enumerate(api_directions_endpoints):\n",
    "    route_id = int(endpoint.split('/')[4])\n",
    "    directions = None\n",
    "    while directions is None:\n",
    "        try:\n",
    "            directions = get_data(endpoint)\n",
    "            # print(f'[{i}] Got directions for route {route_id}')\n",
    "        except requests.exceptions.HTTPError:\n",
    "            # print(f'Failed to get directions for route {route_id}. Retrying in 30 seconds...')\n",
    "            time.sleep(30)\n",
    "            continue\n",
    "    api_all_directions[route_id] = directions\n",
    "api_all_directions = { str(k): v['directions'] for k, v in api_all_directions.items() }\n",
    "# 2m - 3m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all([str(direction['route_id']) == str(k) for k, v in api_all_directions.items() for direction in v])\n",
    "\n",
    "API_DIRECTIONS_LIST = [direction for k, v in api_all_directions.items() for direction in v]\n",
    "\n",
    "API_DF_DIRECTIONS = pd.DataFrame(API_DIRECTIONS_LIST)[['route_id', 'route_type', 'direction_id', 'direction_name']]\n",
    "API_DF_DIRECTIONS.to_csv('../local/ptv-api/all_directions.csv', index=False)\n",
    "assert API_DF_DIRECTIONS[['route_id', 'route_type']].value_counts().max() <= 2\n",
    "\n",
    "API_DF_DIRECTIONS = pd.read_csv('../local/ptv-api/all_directions.csv')\n",
    "\n",
    "API_route_rtds = API_DF_DIRECTIONS[['route_id', 'route_type', 'direction_id']].values\n",
    "API_route_rtds = [(str(r), str(t), str(d)) for r, t, d in API_route_rtds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_STOPS_dict = {}\n",
    "for i, (route_id, route_type, direction_id) in enumerate(API_route_rtds):\n",
    "    # print(f'[{i}] Getting stops for route {route_id}, route type {route_type}, direction {direction_id}')\n",
    "    endpoint = f'/v3/stops/route/{route_id}/route_type/{route_type}?direction_id={direction_id}&include_geopath=true'\n",
    "    stops = None\n",
    "    while stops is None:\n",
    "        try:\n",
    "            stops = get_data(endpoint)\n",
    "            # print(f'[{i}] Got stops for route {route_id}')\n",
    "        except requests.exceptions.HTTPError:\n",
    "            # print(f'Failed to get stops for route {route_id}. Retrying in 30 seconds...')\n",
    "            time.sleep(30)\n",
    "            continue\n",
    "    API_STOPS_dict[route_id] = API_STOPS_dict.get(route_id, {})\n",
    "    API_STOPS_dict[route_id][direction_id] = stops\n",
    "# 3m - 5m\n",
    "    \n",
    "API_STOPS_dict = { str(k): { str(k2): v2 for k2, v2 in v.items()} for k, v in API_STOPS_dict.items() }\n",
    "with open('../local/ptv-api/all_stops_by_direction.json', 'w') as f:\n",
    "    f.write(json.dumps(API_STOPS_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_STOPS_STOPS = []\n",
    "API_STOPS_GEOPATHS = []\n",
    "for route_id, route_type, direction_id in API_route_rtds:\n",
    "    stops = API_STOPS_dict[route_id][direction_id]['stops']\n",
    "    for stop in stops:\n",
    "        if 'stop_ticket' not in stop:\n",
    "            # print(f'Route {route_id} has no ticket key for stop {stop[\"stop_id\"]}')\n",
    "            continue\n",
    "        if stop['stop_ticket'] is None:\n",
    "            # print(f'Route {route_id}: stop {stop[\"stop_id\"]}: stop ticket is None. Skipping...')\n",
    "            continue\n",
    "        for k, v in stop['stop_ticket'].items():\n",
    "            k = f'stop_{k}'\n",
    "            assert k not in stop, f'Key {k} already exists in stop'\n",
    "            stop[k] = v\n",
    "        if 'route_id' not in stop:\n",
    "            stop['route_id'] = route_id\n",
    "        if 'route_type' not in stop:\n",
    "            stop['route_type'] = route_type\n",
    "        if 'direction_id' not in stop:\n",
    "            stop['direction_id'] = direction_id\n",
    "        API_STOPS_STOPS.append(stop)\n",
    "    geopath = API_STOPS_dict[route_id][direction_id]['geopath']\n",
    "    for path in geopath:\n",
    "        if 'route_id' not in path:\n",
    "            path['route_id'] = route_id\n",
    "        if 'route_type' not in path:\n",
    "            path['route_type'] = route_type\n",
    "        if 'direction_id' not in path:\n",
    "            path['direction_id'] = direction_id\n",
    "        API_STOPS_GEOPATHS.append(path)\n",
    "        \n",
    "with open('../local/ptv-api/all_stops_stops.json', 'w') as f:\n",
    "    f.write(json.dumps(API_STOPS_STOPS))\n",
    "with open('../local/ptv-api/all_stops_geopaths.json', 'w') as f:\n",
    "    f.write(json.dumps(API_STOPS_GEOPATHS))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "API_STOPS_STOPS = json.load(open('../local/ptv-api/all_stops_stops.json'))\n",
    "API_STOPS_GEOPATHS = json.load(open('../local/ptv-api/all_stops_geopaths.json'))\n",
    "\n",
    "API_DF_STOPS = pd.DataFrame(API_STOPS_STOPS)\n",
    "API_DF_STOPS.drop(columns=['disruption_ids'], inplace=True)\n",
    "API_DF_STOPS['stop_ticket_zones'] = API_DF_STOPS['stop_ticket_zones'].apply(lambda x: ', '.join(map(str, x)) if isinstance(x, list) else x)\n",
    "API_DF_STOPS.drop(columns=['stop_ticket'], inplace=True)\n",
    "API_DF_STOPS['stop_is_regional'] = API_DF_STOPS['stop_zone'].apply(lambda x: 'Regional' in x)\n",
    "API_DF_STOPS['stop_zones'] = API_DF_STOPS['stop_ticket_zones']\n",
    "API_DF_STOPS.drop(columns=['stop_ticket_zones', 'stop_zone'], inplace=True)\n",
    "API_DF_STOPS = API_DF_STOPS[['stop_id', 'stop_name', 'stop_suburb', 'stop_latitude', 'stop_longitude', 'stop_sequence', 'route_id', 'direction_id',  'route_type',  'stop_landmark', 'stop_zones', 'stop_ticket_type', 'stop_is_free_fare_zone', 'stop_is_regional', 'stop_ticket_machine', 'stop_ticket_checks', 'stop_vline_reservation']]\n",
    "\n",
    "API_DF_STOPS.to_csv('../local/ptv-api/all_stops_stops.csv', index=False)\n",
    "API_DF_STOPS = pd.read_csv('../local/ptv-api/all_stops_stops.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_DF_STOPS_MIN = API_DF_STOPS[['stop_id', 'stop_name', 'stop_suburb', 'stop_latitude', 'stop_longitude']].drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stop_name         2\n",
       "stop_suburb       1\n",
       "stop_latitude     1\n",
       "stop_longitude    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "API_DF_STOPS_MIN.groupby('stop_id').aggregate({'stop_name': 'nunique', 'stop_suburb': 'nunique', 'stop_latitude': 'nunique', 'stop_longitude': 'nunique'}).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_DF_STOPS_MIN_GROUP = API_DF_STOPS_MIN.groupby('stop_id').aggregate({'stop_name': 'unique', 'stop_suburb': 'unique', 'stop_latitude': 'unique', 'stop_longitude': 'unique'})\n",
    "# 7s - 9s\n",
    "assert API_DF_STOPS_MIN_GROUP['stop_suburb'].apply(lambda x: len(x) == 1).all()\n",
    "assert API_DF_STOPS_MIN_GROUP['stop_latitude'].apply(lambda x: len(x) == 1).all()\n",
    "assert API_DF_STOPS_MIN_GROUP['stop_longitude'].apply(lambda x: len(x) == 1).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stop_name</th>\n",
       "      <th>stop_suburb</th>\n",
       "      <th>stop_latitude</th>\n",
       "      <th>stop_longitude</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stop_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>[Berwick Station, Berwick Railway Station]</td>\n",
       "      <td>[Berwick]</td>\n",
       "      <td>[-38.04041]</td>\n",
       "      <td>[145.345718]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>[Broadmeadows Station, Broadmeadows Railway St...</td>\n",
       "      <td>[Broadmeadows]</td>\n",
       "      <td>[-37.6830521]</td>\n",
       "      <td>[144.919617]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>[Caulfield Station, Caulfield Railway Station]</td>\n",
       "      <td>[Caulfield East]</td>\n",
       "      <td>[-37.8774567]</td>\n",
       "      <td>[145.042526]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>[Clayton Station, Clayton Railway Station]</td>\n",
       "      <td>[Clayton]</td>\n",
       "      <td>[-37.9246826]</td>\n",
       "      <td>[145.120529]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>[Craigieburn Station, Craigieburn Railway Stat...</td>\n",
       "      <td>[Craigieburn]</td>\n",
       "      <td>[-37.6019249]</td>\n",
       "      <td>[144.943314]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>[Dandenong Station, Dandenong Railway Station]</td>\n",
       "      <td>[Dandenong]</td>\n",
       "      <td>[-37.9899673]</td>\n",
       "      <td>[145.209732]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>[Essendon Station, Essendon Railway Station]</td>\n",
       "      <td>[Essendon]</td>\n",
       "      <td>[-37.75601]</td>\n",
       "      <td>[144.9162]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071</th>\n",
       "      <td>[Flinders Street Station, Flinders Street Rail...</td>\n",
       "      <td>[Melbourne City]</td>\n",
       "      <td>[-37.81831]</td>\n",
       "      <td>[144.966965]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>[Footscray Station, Footscray Railway Station]</td>\n",
       "      <td>[Footscray]</td>\n",
       "      <td>[-37.8010864]</td>\n",
       "      <td>[144.9032]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>[North Melbourne Station, North Melbourne Rail...</td>\n",
       "      <td>[West Melbourne]</td>\n",
       "      <td>[-37.807415]</td>\n",
       "      <td>[144.942566]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1153</th>\n",
       "      <td>[Pakenham Station, Pakenham Railway Station]</td>\n",
       "      <td>[Pakenham]</td>\n",
       "      <td>[-38.0802078]</td>\n",
       "      <td>[145.485977]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1162</th>\n",
       "      <td>[Richmond Station, Richmond Railway Station]</td>\n",
       "      <td>[Richmond]</td>\n",
       "      <td>[-37.8240738]</td>\n",
       "      <td>[144.990158]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1181</th>\n",
       "      <td>[Southern Cross Station, Southern Cross Railwa...</td>\n",
       "      <td>[Melbourne City]</td>\n",
       "      <td>[-37.8183327]</td>\n",
       "      <td>[144.95253]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187</th>\n",
       "      <td>[Sunbury Station, Sunbury Railway Station]</td>\n",
       "      <td>[Sunbury]</td>\n",
       "      <td>[-37.57909]</td>\n",
       "      <td>[144.727325]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1202</th>\n",
       "      <td>[Watergardens Station, Watergardens Railway St...</td>\n",
       "      <td>[Sydenham]</td>\n",
       "      <td>[-37.7011261]</td>\n",
       "      <td>[144.774185]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>[Sunshine Station, Sunshine Railway Station]</td>\n",
       "      <td>[Sunshine]</td>\n",
       "      <td>[-37.7885361]</td>\n",
       "      <td>[144.832886]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 stop_name       stop_suburb  \\\n",
       "stop_id                                                                        \n",
       "1021            [Berwick Station, Berwick Railway Station]         [Berwick]   \n",
       "1028     [Broadmeadows Station, Broadmeadows Railway St...    [Broadmeadows]   \n",
       "1036        [Caulfield Station, Caulfield Railway Station]  [Caulfield East]   \n",
       "1040            [Clayton Station, Clayton Railway Station]         [Clayton]   \n",
       "1044     [Craigieburn Station, Craigieburn Railway Stat...     [Craigieburn]   \n",
       "1049        [Dandenong Station, Dandenong Railway Station]       [Dandenong]   \n",
       "1064          [Essendon Station, Essendon Railway Station]        [Essendon]   \n",
       "1071     [Flinders Street Station, Flinders Street Rail...  [Melbourne City]   \n",
       "1072        [Footscray Station, Footscray Railway Station]       [Footscray]   \n",
       "1144     [North Melbourne Station, North Melbourne Rail...  [West Melbourne]   \n",
       "1153          [Pakenham Station, Pakenham Railway Station]        [Pakenham]   \n",
       "1162          [Richmond Station, Richmond Railway Station]        [Richmond]   \n",
       "1181     [Southern Cross Station, Southern Cross Railwa...  [Melbourne City]   \n",
       "1187            [Sunbury Station, Sunbury Railway Station]         [Sunbury]   \n",
       "1202     [Watergardens Station, Watergardens Railway St...        [Sydenham]   \n",
       "1218          [Sunshine Station, Sunshine Railway Station]        [Sunshine]   \n",
       "\n",
       "         stop_latitude stop_longitude  \n",
       "stop_id                                \n",
       "1021       [-38.04041]   [145.345718]  \n",
       "1028     [-37.6830521]   [144.919617]  \n",
       "1036     [-37.8774567]   [145.042526]  \n",
       "1040     [-37.9246826]   [145.120529]  \n",
       "1044     [-37.6019249]   [144.943314]  \n",
       "1049     [-37.9899673]   [145.209732]  \n",
       "1064       [-37.75601]     [144.9162]  \n",
       "1071       [-37.81831]   [144.966965]  \n",
       "1072     [-37.8010864]     [144.9032]  \n",
       "1144      [-37.807415]   [144.942566]  \n",
       "1153     [-38.0802078]   [145.485977]  \n",
       "1162     [-37.8240738]   [144.990158]  \n",
       "1181     [-37.8183327]    [144.95253]  \n",
       "1187       [-37.57909]   [144.727325]  \n",
       "1202     [-37.7011261]   [144.774185]  \n",
       "1218     [-37.7885361]   [144.832886]  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "API_DF_STOPS_MIN_GROUP[API_DF_STOPS_MIN_GROUP['stop_name'].apply(lambda x: len(x) > 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stop_id</th>\n",
       "      <th>stop_name</th>\n",
       "      <th>stop_suburb</th>\n",
       "      <th>stop_latitude</th>\n",
       "      <th>stop_longitude</th>\n",
       "      <th>stop_sequence</th>\n",
       "      <th>route_id</th>\n",
       "      <th>direction_id</th>\n",
       "      <th>route_type</th>\n",
       "      <th>stop_landmark</th>\n",
       "      <th>stop_zones</th>\n",
       "      <th>stop_ticket_type</th>\n",
       "      <th>stop_is_free_fare_zone</th>\n",
       "      <th>stop_is_regional</th>\n",
       "      <th>stop_ticket_machine</th>\n",
       "      <th>stop_ticket_checks</th>\n",
       "      <th>stop_vline_reservation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60197</th>\n",
       "      <td>1040</td>\n",
       "      <td>Clayton Railway Station</td>\n",
       "      <td>Clayton</td>\n",
       "      <td>-37.924683</td>\n",
       "      <td>145.120529</td>\n",
       "      <td>41</td>\n",
       "      <td>1721</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60235</th>\n",
       "      <td>1040</td>\n",
       "      <td>Clayton Railway Station</td>\n",
       "      <td>Clayton</td>\n",
       "      <td>-37.924683</td>\n",
       "      <td>145.120529</td>\n",
       "      <td>0</td>\n",
       "      <td>1721</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61822</th>\n",
       "      <td>1040</td>\n",
       "      <td>Clayton Railway Station</td>\n",
       "      <td>Clayton</td>\n",
       "      <td>-37.924683</td>\n",
       "      <td>145.120529</td>\n",
       "      <td>25</td>\n",
       "      <td>1823</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61852</th>\n",
       "      <td>1040</td>\n",
       "      <td>Clayton Railway Station</td>\n",
       "      <td>Clayton</td>\n",
       "      <td>-37.924683</td>\n",
       "      <td>145.120529</td>\n",
       "      <td>6</td>\n",
       "      <td>1823</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61883</th>\n",
       "      <td>1040</td>\n",
       "      <td>Clayton Railway Station</td>\n",
       "      <td>Clayton</td>\n",
       "      <td>-37.924683</td>\n",
       "      <td>145.120529</td>\n",
       "      <td>18</td>\n",
       "      <td>1824</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61911</th>\n",
       "      <td>1040</td>\n",
       "      <td>Clayton Railway Station</td>\n",
       "      <td>Clayton</td>\n",
       "      <td>-37.924683</td>\n",
       "      <td>145.120529</td>\n",
       "      <td>6</td>\n",
       "      <td>1824</td>\n",
       "      <td>39</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62430</th>\n",
       "      <td>1040</td>\n",
       "      <td>Clayton Railway Station</td>\n",
       "      <td>Clayton</td>\n",
       "      <td>-37.924683</td>\n",
       "      <td>145.120529</td>\n",
       "      <td>22</td>\n",
       "      <td>5838</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62455</th>\n",
       "      <td>1040</td>\n",
       "      <td>Clayton Railway Station</td>\n",
       "      <td>Clayton</td>\n",
       "      <td>-37.924683</td>\n",
       "      <td>145.120529</td>\n",
       "      <td>0</td>\n",
       "      <td>5838</td>\n",
       "      <td>43</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       stop_id                stop_name stop_suburb  stop_latitude  \\\n",
       "60197     1040  Clayton Railway Station     Clayton     -37.924683   \n",
       "60235     1040  Clayton Railway Station     Clayton     -37.924683   \n",
       "61822     1040  Clayton Railway Station     Clayton     -37.924683   \n",
       "61852     1040  Clayton Railway Station     Clayton     -37.924683   \n",
       "61883     1040  Clayton Railway Station     Clayton     -37.924683   \n",
       "61911     1040  Clayton Railway Station     Clayton     -37.924683   \n",
       "62430     1040  Clayton Railway Station     Clayton     -37.924683   \n",
       "62455     1040  Clayton Railway Station     Clayton     -37.924683   \n",
       "\n",
       "       stop_longitude  stop_sequence  route_id  direction_id  route_type  \\\n",
       "60197      145.120529             41      1721             0           3   \n",
       "60235      145.120529              0      1721            23           3   \n",
       "61822      145.120529             25      1823             0           3   \n",
       "61852      145.120529              6      1823            11           3   \n",
       "61883      145.120529             18      1824             0           3   \n",
       "61911      145.120529              6      1824            39           3   \n",
       "62430      145.120529             22      5838             0           3   \n",
       "62455      145.120529              0      5838            43           3   \n",
       "\n",
       "      stop_landmark stop_zones  stop_ticket_type  stop_is_free_fare_zone  \\\n",
       "60197           NaN          2               NaN                   False   \n",
       "60235           NaN          2               NaN                   False   \n",
       "61822           NaN          2               NaN                   False   \n",
       "61852           NaN          2               NaN                   False   \n",
       "61883           NaN          2               NaN                   False   \n",
       "61911           NaN          2               NaN                   False   \n",
       "62430           NaN          2               NaN                   False   \n",
       "62455           NaN          2               NaN                   False   \n",
       "\n",
       "       stop_is_regional  stop_ticket_machine  stop_ticket_checks  \\\n",
       "60197              True                False               False   \n",
       "60235              True                False               False   \n",
       "61822              True                False               False   \n",
       "61852              True                False               False   \n",
       "61883              True                False               False   \n",
       "61911              True                False               False   \n",
       "62430              True                False               False   \n",
       "62455              True                False               False   \n",
       "\n",
       "       stop_vline_reservation  \n",
       "60197                   False  \n",
       "60235                   False  \n",
       "61822                   False  \n",
       "61852                   False  \n",
       "61883                   False  \n",
       "61911                   False  \n",
       "62430                   False  \n",
       "62455                   False  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "API_DF_STOPS[API_DF_STOPS['stop_name'] == 'Clayton Railway Station']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
